{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Postgres Message Queue (PGMQ)","text":"<p>A lightweight message queue. Like AWS SQS and RSMQ but on Postgres.</p> <p> </p> <p>Documentation: https://pgmq.github.io/pgmq/</p> <p>Source: https://github.com/pgmq/pgmq</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Lightweight - No background worker or external dependencies, just Postgres SQL objects</li> <li>Guaranteed \"exactly once\" delivery of messages to a consumer within a visibility timeout</li> <li>API parity with AWS SQS and RSMQ</li> <li>FIFO (First-In-First-Out) queues with message group keys for ordered processing</li> <li>Topic-based routing with wildcard patterns for publish-subscribe and content-based routing</li> <li>Messages stay in the queue until explicitly removed</li> <li>Messages can be archived, instead of deleted, for long-term retention and replayability</li> </ul> <p>Supported on Postgres 14-18.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Postgres Message Queue (PGMQ)</li> <li>Features</li> <li>Table of Contents</li> <li>Installation<ul> <li>Docker</li> <li>SQL Only</li> <li>Updating</li> </ul> </li> <li>Client Libraries</li> <li>SQL Examples<ul> <li>Creating a queue</li> <li>Send two messages</li> <li>Read messages</li> <li>Pop a message</li> <li>Archive a message</li> <li>Delete a message</li> <li>Drop a queue</li> </ul> </li> <li>Visibility Timeout (vt)</li> <li>Who uses pgmq?</li> <li>\u2728 Contributors</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>PGMQ can be run on any existing Postgres instance or installed as a Postgres Extension. See INSTALLATION.md for the full installation guide including a comparison of the Postgres Extension vs the SQL-only installation.</p>"},{"location":"#docker","title":"Docker","text":"<p>The fastest way to get started is by running the Docker image, where PGMQ comes pre-installed as an extension in Postgres.</p> <pre><code>docker run -d --name pgmq-postgres -e POSTGRES_PASSWORD=postgres -p 5432:5432 ghcr.io/pgmq/pg18-pgmq:v1.10.0\n</code></pre> <p>Then connect and enable PGMQ:</p> <pre><code>psql postgres://postgres:postgres@localhost:5432/postgres\n</code></pre> <pre><code>CREATE EXTENSION pgmq;\n</code></pre>"},{"location":"#sql-only","title":"SQL Only","text":"<p>You can also use psql to install PGMQ's objects directly into the pgmq schema in Postgres. Use this method if you are running someplace that does not natively support the PGMQ Extension. Read these considerations before you decide.</p> <pre><code>git clone https://github.com/pgmq/pgmq.git\n\ncd pgmq\n\npsql -f pgmq-extension/sql/pgmq.sql postgres://postgres:postgres@localhost:5432/postgres\n</code></pre>"},{"location":"#updating","title":"Updating","text":"<p>To update PGMQ versions, follow the instructions in UPDATING.md.</p>"},{"location":"#client-libraries","title":"Client Libraries","text":"<ul> <li>Rust</li> <li>Python (only for psycopg3)</li> </ul> <p>Community</p> <ul> <li>.NET</li> <li>Dart</li> <li>Elixir + Broadway</li> <li>Elixir</li> <li>Go</li> <li>Haskell</li> <li>Java (JDBC)</li> <li>Java (Spring Boot)</li> <li>Javascript (NodeJs)</li> <li>Kotlin JVM (JDBC)</li> <li>Kotlin Multiplatform (sqlx4k)</li> <li>PHP (non blocking)</li> <li>Python (with SQLAlchemy)</li> <li>REST-API (Bun + Elysia)</li> <li>Ruby</li> <li>TypeScript (Deno)</li> <li>TypeScript (NodeJs + Prisma) </li> <li>TypeScript (NodeJs + Midway.js)</li> </ul>"},{"location":"#sql-examples","title":"SQL Examples","text":"<pre><code># Connect to Postgres\npsql postgres://postgres:postgres@0.0.0.0:5432/postgres\n</code></pre> <pre><code>-- create the extension in the \"pgmq\" schema\nCREATE EXTENSION pgmq;\n</code></pre>"},{"location":"#creating-a-queue","title":"Creating a queue","text":"<p>Every queue is its own table in the <code>pgmq</code> schema. The table name is the queue name prefixed with <code>q_</code>. For example, <code>pgmq.q_my_queue</code> is the table for the queue <code>my_queue</code>.</p> <pre><code>-- creates the queue\nSELECT pgmq.create('my_queue');\n</code></pre> <pre><code> create\n-------------\n\n(1 row)\n</code></pre>"},{"location":"#send-two-messages","title":"Send two messages","text":"<pre><code>-- messages are sent as JSON\nSELECT * from pgmq.send(\n  queue_name  =&gt; 'my_queue',\n  msg         =&gt; '{\"foo\": \"bar1\"}'\n);\n</code></pre> <p>The message id is returned from the send function.</p> <pre><code> send\n-----------\n         1\n(1 row)\n</code></pre> <pre><code>-- Optionally provide a delay\n-- this message will be on the queue but unable to be consumed for 5 seconds\nSELECT * from pgmq.send(\n  queue_name =&gt; 'my_queue',\n  msg        =&gt; '{\"foo\": \"bar2\"}',\n  delay      =&gt; 5\n);\n</code></pre> <pre><code> send\n-----------\n         2\n(1 row)\n</code></pre>"},{"location":"#read-messages","title":"Read messages","text":"<p>Read <code>2</code> message from the queue. Make them invisible for <code>30</code> seconds. If the messages are not deleted or archived within 30 seconds, they will become visible again and can be read by another consumer.</p> <pre><code>SELECT * FROM pgmq.read(\n  queue_name =&gt; 'my_queue',\n  vt         =&gt; 30,\n  qty        =&gt; 2\n);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |     message     | headers \n--------+---------+-------------------------------+-------------------------------+-------------------------------+-----------------+---------\n      1 |       1 | 2026-01-23 20:27:21.7741-06   | 2026-01-23 20:27:31.605236-06 | 2026-01-23 20:28:01.605236-06 | {\"foo\": \"bar1\"} | \n      2 |       1 | 2026-01-23 20:27:26.505063-06 | 2026-01-23 20:27:31.605252-06 | 2026-01-23 20:28:01.605252-06 | {\"foo\": \"bar2\"} | \n</code></pre> <p>If the queue is empty, or if all messages are currently invisible, no rows will be returned.</p> <pre><code>SELECT * FROM pgmq.read(\n  queue_name =&gt; 'my_queue',\n  vt         =&gt; 30,\n  qty        =&gt; 1\n);\n</code></pre> <pre><code> msg_id | read_ct | enqueued_at | last_read_at | vt | message | headers \n--------+---------+-------------+--------------+----+---------+---------\n</code></pre>"},{"location":"#pop-a-message","title":"Pop a message","text":"<pre><code>-- Read a message and immediately delete it from the queue. Returns an empty record if the queue is empty or all messages are invisible.\nSELECT * FROM pgmq.pop('my_queue');\n</code></pre> <pre><code> msg_id | read_ct |         enqueued_at         |         last_read_at          |              vt               |     message     | headers \n--------+---------+-----------------------------+-------------------------------+-------------------------------+-----------------+---------\n      1 |       1 | 2026-01-23 20:27:21.7741-06 | 2026-01-23 20:27:31.605236-06 | 2026-01-23 20:28:01.605236-06 | {\"foo\": \"bar1\"} | \n</code></pre>"},{"location":"#archive-a-message","title":"Archive a message","text":"<p>Archiving a message removes it from the queue and inserts it to the archive table.</p> <pre><code>-- Archive message with msg_id=2.\nSELECT pgmq.archive(\n  queue_name =&gt; 'my_queue',\n  msg_id     =&gt; 2\n);\n</code></pre> <pre><code> archive\n--------------\n t\n(1 row)\n</code></pre> <p>Or archive several messages in one operation using <code>msg_ids</code> (plural) parameter:</p> <p>First, send a batch of messages</p> <pre><code>SELECT pgmq.send_batch(\n  queue_name =&gt; 'my_queue',\n  msgs       =&gt; ARRAY['{\"foo\": \"bar3\"}','{\"foo\": \"bar4\"}','{\"foo\": \"bar5\"}']::jsonb[]\n);\n</code></pre> <pre><code> send_batch \n------------\n          3\n          4\n          5\n(3 rows)\n</code></pre> <p>Then archive them by using the msg_ids (plural) parameter.</p> <pre><code>SELECT pgmq.archive(\n  queue_name =&gt; 'my_queue',\n  msg_ids    =&gt; ARRAY[3, 4, 5]\n);\n</code></pre> <pre><code> archive \n---------\n       3\n       4\n       5\n(3 rows)\n</code></pre> <p>Archive tables can be inspected directly with SQL.  Archive tables have the prefix <code>a_</code> in the <code>pgmq</code> schema.</p> <pre><code>SELECT * FROM pgmq.a_my_queue;\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |          archived_at          |              vt               |     message     | headers \n--------+---------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+-----------------+---------\n      2 |       1 | 2026-01-23 20:32:35.291971-06 | 2026-01-23 20:32:42.938473-06 | 2026-01-23 20:33:20.297454-06 | 2026-01-23 20:33:12.938473-06 | {\"foo\": \"bar2\"} | \n      3 |       0 | 2026-01-23 20:33:25.414914-06 |                               | 2026-01-23 20:33:30.318465-06 | 2026-01-23 20:33:25.415035-06 | {\"foo\": \"bar3\"} | \n      4 |       0 | 2026-01-23 20:33:25.414914-06 |                               | 2026-01-23 20:33:30.318465-06 | 2026-01-23 20:33:25.415035-06 | {\"foo\": \"bar4\"} | \n      5 |       0 | 2026-01-23 20:33:25.414914-06 |                               | 2026-01-23 20:33:30.318465-06 | 2026-01-23 20:33:25.415035-06 | {\"foo\": \"bar5\"} | \n</code></pre>"},{"location":"#delete-a-message","title":"Delete a message","text":"<p>Send another message, so that we can delete it.</p> <pre><code>SELECT pgmq.send('my_queue', '{\"foo\": \"bar6\"}');\n</code></pre> <pre><code> send\n-----------\n        6\n(1 row)\n</code></pre> <p>Delete the message with id <code>6</code> from the queue named <code>my_queue</code>.</p> <pre><code>SELECT pgmq.delete('my_queue', 6);\n</code></pre> <pre><code> delete\n-------------\n t\n(1 row)\n</code></pre>"},{"location":"#drop-a-queue","title":"Drop a queue","text":"<p>Delete the queue <code>my_queue</code>.</p> <pre><code>SELECT pgmq.drop_queue('my_queue');\n</code></pre> <pre><code> drop_queue\n-----------------\n t\n(1 row)\n</code></pre>"},{"location":"#visibility-timeout-vt","title":"Visibility Timeout (vt)","text":"<p>pgmq guarantees exactly once delivery of a message within a visibility timeout. The visibility timeout is the amount of time a message is invisible to other consumers after it has been read by a consumer. If the message is NOT deleted or archived within the visibility timeout, it will become visible again and can be read by another consumer. The visibility timeout is set when a message is read from the queue, via <code>pgmq.read()</code>. It is recommended to set a <code>vt</code> value that is greater than the expected time it takes to process a message. After the application successfully processes the message, it should call <code>pgmq.delete()</code> to completely remove the message from the queue or <code>pgmq.archive()</code> to move it to the archive table for the queue.</p>"},{"location":"#who-uses-pgmq","title":"Who uses pgmq?","text":"<p>As the pgmq community grows, we'd love to see who is using it. Please send a PR with your company name and @githubhandle.</p> <p>Currently, officially using pgmq:</p> <ol> <li>Tembo [@Tembo-io]</li> <li>Supabase [@Supabase]</li> <li>Sprinters [@sprinters-sh]</li> <li>pgflow [@pgflow-dev/pgflow]</li> </ol>"},{"location":"#contributors","title":"\u2728 Contributors","text":"<p>Thanks goes to these incredible people:</p> <p> </p>"},{"location":"fifo-queues/","title":"FIFO Queues","text":"<p>PGMQ supports FIFO (First-In-First-Out) queues with message group keys, similar to AWS SQS FIFO queues. This feature allows you to ensure strict ordering of messages within logical groups while still allowing parallel processing across different groups.</p>"},{"location":"fifo-queues/#overview","title":"Overview","text":"<p>FIFO queues in PGMQ work by using message headers to specify group identifiers. Messages with the same group ID are processed in strict order, while messages from different groups can be processed in parallel.</p>"},{"location":"fifo-queues/#key-features","title":"Key Features","text":"<ul> <li>Strict ordering within groups: Messages with the same FIFO group ID are processed in the exact order they were sent</li> <li>Parallel processing across groups: Different FIFO groups can be processed simultaneously</li> <li>Backward compatibility: Existing queues work unchanged; FIFO is opt-in via headers</li> <li>Visibility timeout support: FIFO respects visibility timeouts to prevent duplicate processing</li> <li>Performance optimized: Uses efficient indexing for FIFO group lookups</li> </ul>"},{"location":"fifo-queues/#how-it-works","title":"How It Works","text":""},{"location":"fifo-queues/#message-group-ids","title":"Message Group IDs","text":"<p>FIFO ordering is controlled by the <code>x-pgmq-group</code> header value:</p> <pre><code>-- Send messages to the same FIFO group\nSELECT pgmq.send('my_queue', '{\"order\": 1}', '{\"x-pgmq-group\": \"user123\"}');\nSELECT pgmq.send('my_queue', '{\"order\": 2}', '{\"x-pgmq-group\": \"user123\"}');\n\n-- Send message to different FIFO group\nSELECT pgmq.send('my_queue', '{\"order\": 1}', '{\"x-pgmq-group\": \"user456\"}');\n</code></pre>"},{"location":"fifo-queues/#reading-fifo-messages","title":"Reading FIFO Messages","text":"<p>PGMQ provides two FIFO reading strategies. Choose the one that best fits your workload:</p> <ul> <li><code>pgmq.read_grouped_rr(...)</code> (Round-Robin, layered interleaving): Fairly interleaves messages across groups. Great for multi-tenant and user-centric workloads.</li> <li><code>pgmq.read_grouped(...)</code> (SQS-style throughput): Fills batches from the oldest eligible group first, returning multiple messages from the same group for throughput.</li> </ul> <pre><code>-- Fair distribution across groups (round-robin, layered)\nSELECT * FROM pgmq.read_grouped_rr('my_queue', 30, 5);\n\n-- Throughput-optimized, SQS-style batch filling\nSELECT * FROM pgmq.read_grouped('my_queue', 30, 5);\n</code></pre> <p>Round-robin (RR) will: - Interleave across groups in layers, preserving order within each group - Return up to the requested quantity across groups - Prevent starvation of smaller/less-active groups</p> <p>SQS-style will: - Fill the batch from the earliest eligible group first - Return multiple messages from the same group when available - Move to other groups only if needed to fill the batch</p>"},{"location":"fifo-queues/#default-group-behavior","title":"Default Group Behavior","text":"<p>Messages without the <code>x-pgmq-group</code> header are treated as belonging to a single default group:</p> <pre><code>-- These messages will be processed in FIFO order relative to each other\nSELECT pgmq.send('my_queue', '{\"message\": \"first\"}');\nSELECT pgmq.send('my_queue', '{\"message\": \"second\"}');\n</code></pre>"},{"location":"fifo-queues/#api-reference","title":"API Reference","text":""},{"location":"fifo-queues/#reading-functions","title":"Reading Functions","text":""},{"location":"fifo-queues/#pgmqread_grouped_rrqueue_name-vt-qty","title":"<code>pgmq.read_grouped_rr(queue_name, vt, qty)</code>","text":"<p>Read messages while respecting FIFO ordering within groups.</p> <p>Parameters: - <code>queue_name</code> (text): Name of the queue - <code>vt</code> (integer): Visibility timeout in seconds - <code>qty</code> (integer): Maximum number of messages to read</p>"},{"location":"fifo-queues/#pgmqread_grouped_rr_with_pollqueue_name-vt-qty-max_poll_seconds-poll_interval_ms","title":"<code>pgmq.read_grouped_rr_with_poll(queue_name, vt, qty, max_poll_seconds, poll_interval_ms)</code>","text":"<p>Same as <code>read_grouped_rr()</code> but with polling support for real-time processing.</p>"},{"location":"fifo-queues/#pgmqread_groupedqueue_name-vt-qty","title":"<code>pgmq.read_grouped(queue_name, vt, qty)</code>","text":"<p>Read messages with AWS SQS FIFO-style batch retrieval behavior. Unlike <code>read_grouped_rr()</code> which interleaves fairly across groups, this function attempts to return as many messages as possible from the same message group to maximize throughput for related messages.</p> <p>Behavior: - Prioritizes filling the batch from the earliest message group first - Returns multiple messages from the same group when available - Only moves to other groups if the batch cannot be filled from the first group - Maintains strict FIFO ordering within each group</p>"},{"location":"fifo-queues/#pgmqread_grouped_with_pollqueue_name-vt-qty-max_poll_seconds-poll_interval_ms","title":"<code>pgmq.read_grouped_with_poll(queue_name, vt, qty, max_poll_seconds, poll_interval_ms)</code>","text":"<p>Same as <code>read_grouped()</code> but with polling support for real-time processing.</p>"},{"location":"fifo-queues/#utility-functions","title":"Utility Functions","text":""},{"location":"fifo-queues/#pgmqcreate_fifo_indexqueue_name","title":"<code>pgmq.create_fifo_index(queue_name)</code>","text":"<p>Creates a GIN index on the headers column to improve FIFO read performance. Recommended when using FIFO functionality frequently.</p>"},{"location":"fifo-queues/#pgmqcreate_fifo_indexes_all","title":"<code>pgmq.create_fifo_indexes_all()</code>","text":"<p>Creates FIFO indexes on all existing queues.</p>"},{"location":"fifo-queues/#usage-patterns","title":"Usage Patterns","text":""},{"location":"fifo-queues/#1-user-specific-processing","title":"1. User-Specific Processing","text":"<p>Ensure messages for each user are processed in order:</p> <pre><code>-- User 1 messages\nSELECT pgmq.send('user_events', '{\"action\": \"login\"}', '{\"x-pgmq-group\": \"user_123\"}');\nSELECT pgmq.send('user_events', '{\"action\": \"purchase\"}', '{\"x-pgmq-group\": \"user_123\"}');\n\n-- User 2 messages (can be processed in parallel)\nSELECT pgmq.send('user_events', '{\"action\": \"login\"}', '{\"x-pgmq-group\": \"user_456\"}');\n</code></pre>"},{"location":"fifo-queues/#2-order-processing","title":"2. Order Processing","text":"<p>Maintain order integrity for financial transactions:</p> <pre><code>-- Order lifecycle events\nSELECT pgmq.send('orders', '{\"order_id\": \"ord_1\", \"action\": \"create\"}', '{\"x-pgmq-group\": \"ord_1\"}');\nSELECT pgmq.send('orders', '{\"order_id\": \"ord_1\", \"action\": \"payment\"}', '{\"x-pgmq-group\": \"ord_1\"}');\nSELECT pgmq.send('orders', '{\"order_id\": \"ord_1\", \"action\": \"fulfill\"}', '{\"x-pgmq-group\": \"ord_1\"}');\n</code></pre>"},{"location":"fifo-queues/#3-document-processing","title":"3. Document Processing","text":"<p>Process document versions in sequence:</p> <pre><code>-- Document updates\nSELECT pgmq.send('docs', '{\"doc_id\": \"doc_1\", \"version\": 1}', '{\"x-pgmq-group\": \"doc_1\"}');\nSELECT pgmq.send('docs', '{\"doc_id\": \"doc_1\", \"version\": 2}', '{\"x-pgmq-group\": \"doc_1\"}');\n</code></pre>"},{"location":"fifo-queues/#performance-considerations","title":"Performance Considerations","text":""},{"location":"fifo-queues/#indexing","title":"Indexing","text":"<p>Create FIFO indexes for better performance:</p> <pre><code>-- For a specific queue\nSELECT pgmq.create_fifo_index('my_queue');\n\n-- For all queues\nSELECT pgmq.create_fifo_indexes_all();\n</code></pre>"},{"location":"fifo-queues/#group-distribution","title":"Group Distribution","text":"<ul> <li>Good: Many small groups with few messages each</li> <li>Avoid: Few large groups with many messages (reduces parallelism)</li> </ul>"},{"location":"fifo-queues/#message-processing","title":"Message Processing","text":"<ul> <li>Process and delete/archive messages promptly to avoid blocking subsequent messages</li> <li>Use appropriate visibility timeouts to handle processing failures</li> <li>Monitor queue metrics to identify bottlenecks</li> </ul>"},{"location":"fifo-queues/#error-handling","title":"Error Handling","text":""},{"location":"fifo-queues/#visibility-timeout-expiry","title":"Visibility Timeout Expiry","text":"<p>If message processing fails, the visibility timeout will expire and the message becomes available again:</p> <pre><code>-- Message fails processing, timeout expires\n-- Next read_grouped() call will return the same message for retry\n</code></pre>"},{"location":"fifo-queues/#manual-retry","title":"Manual Retry","text":"<p>Force a message to be immediately available:</p> <pre><code>-- Set visibility timeout to 0 for immediate retry\nSELECT pgmq.set_vt('my_queue', 123, 0);\n</code></pre>"},{"location":"fifo-queues/#dead-letter-handling","title":"Dead Letter Handling","text":"<p>Archive messages that fail repeatedly:</p> <pre><code>-- After max retries, archive the problematic message\nSELECT pgmq.archive('my_queue', 123);\n</code></pre>"},{"location":"fifo-queues/#migration-from-regular-queues","title":"Migration from Regular Queues","text":"<p>FIFO functionality is backward compatible:</p> <ol> <li>Existing code continues to work: <code>pgmq.read()</code> functions unchanged</li> <li>Gradual adoption: Start using <code>pgmq.read_grouped_rr()</code> or <code>pgmq.read_grouped()</code> for new consumers</li> <li>Mixed usage: Some consumers can use FIFO, others regular reads</li> <li>Performance: Add FIFO indexes when ready to optimize</li> </ol>"},{"location":"fifo-queues/#fifo-reading-strategies","title":"FIFO Reading Strategies","text":"<p>PGMQ provides two different FIFO reading strategies to suit different use cases:</p>"},{"location":"fifo-queues/#fair-distribution-pgmqread_grouped_rr","title":"Fair Distribution (<code>pgmq.read_grouped_rr()</code>)","text":"<p>Interleaves messages across FIFO groups in layers:</p> <pre><code>-- With groups A (5 messages), B (3 messages), C (2 messages)\nSELECT * FROM pgmq.read_grouped_rr('queue', 30, 10);\n-- Returns (layered interleaving): A1, B1, C1, A2, B2, C2, A3, B3, A4, ...\n</code></pre> <p>Best for: - Ensuring fair processing across all groups - Preventing starvation of groups with fewer messages - Load balancing across different workflows</p>"},{"location":"fifo-queues/#throughput-optimization-pgmqread_grouped","title":"Throughput Optimization (<code>pgmq.read_grouped()</code>)","text":"<p>Attempts to fill the batch from the earliest group first:</p> <pre><code>-- With groups A (5 messages), B (3 messages), C (2 messages)\nSELECT * FROM pgmq.read_grouped('queue', 30, 10);\n-- Returns: 10 messages (5 from A + 3 from B + 2 from C)\n\nSELECT * FROM pgmq.read_grouped('queue', 30, 3);\n-- Returns: 3 messages (all from group A)\n</code></pre> <p>Best for: - Maximizing throughput for related messages - Processing workflows where batching related messages is beneficial - Mimicking AWS SQS FIFO behavior exactly</p>"},{"location":"fifo-queues/#choosing-the-right-strategy","title":"Choosing the Right Strategy","text":"Scenario Recommended Function Reason Multi-tenant processing <code>read_grouped_rr()</code> Ensures fair resource allocation Order processing pipeline <code>read_grouped()</code> Related orders processed together User activity streams <code>read_grouped_rr()</code> Prevents one active user from blocking others Document workflows <code>read_grouped()</code> Process all versions of a document together Financial transactions <code>read_grouped()</code> Batch related transactions for efficiency"},{"location":"fifo-queues/#comparison-with-aws-sqs-fifo","title":"Comparison with AWS SQS FIFO","text":"Feature PGMQ FIFO (RR) PGMQ read_grouped AWS SQS FIFO Group-based ordering \u2705 \u2705 \u2705 Parallel group processing \u2705 \u2705 \u2705 Batch retrieval strategy Fair (layered interleaving) Throughput-optimized Throughput-optimized Message deduplication \u274c \u274c \u2705 Throughput limits No limits No limits 300 TPS per group Exactly-once delivery \u274c \u274c \u2705 Cost Free Free Pay per request"},{"location":"fifo-queues/#best-practices","title":"Best Practices","text":"<ol> <li>Choose appropriate group keys: Balance between ordering requirements and parallelism</li> <li>Create FIFO indexes: Improve performance for frequently used queues</li> <li>Monitor group distribution: Ensure even distribution across groups</li> <li>Handle failures gracefully: Implement retry logic and dead letter handling</li> <li>Test thoroughly: Verify ordering behavior under load</li> <li>Use meaningful group IDs: Make debugging and monitoring easier</li> </ol>"},{"location":"fifo-queues/#examples","title":"Examples","text":"<p>See examples/fifo_example.sql for comprehensive usage examples.</p>"},{"location":"partitioned-queues/","title":"Partitioned Queues","text":"<p>You will need to install pg_partman if you want to use <code>pgmq</code> partitioned queues.</p>"},{"location":"partitioned-queues/#overview","title":"Overview","text":"<p><code>pgmq</code> queue tables can be created as a partitioned table by using <code>pgmq.create_partitioned()</code>. pg_partman handles all maintenance of queue tables. This includes creating new partitions and dropping old partitions.</p> <p>Partitions behavior is configured at the time queues are created, via <code>pgmq.create_partitioned()</code>. This function has three parameters:</p>"},{"location":"partitioned-queues/#parameters","title":"Parameters","text":"<p><code>queue_name: text</code>: The name of the queue. Queues are Postgres tables prepended with <code>q_</code>. For example, <code>q_my_queue</code>. The archive is instead prefixed by <code>a_</code>, for example <code>a_my_queue</code>.</p> <p><code>partition_interval: text</code> - The interval at which partitions are created. This can be either any valid Postgres <code>Duration</code> supported by pg_partman, or an integer value. When it is a duration, queues are partitioned by the time at which messages are sent to the table (<code>enqueued_at</code>). A value of <code>'daily'</code> would create a new partition each day. When it is an integer value, queues are partitioned by the <code>msg_id</code>. A value of <code>'100'</code> will create a new partition every 100 messages. The value must agree with <code>retention_interval</code> (time based or numeric). The default value is <code>'10000'</code>. For archive table, when interval is an integer value, then it will be partitioned by <code>msg_id</code>. In case of duration it will be partitioned on <code>archived_at</code> unlike queue table.</p> <p><code>retention_interval: text</code> - The interval for retaining partitions. This can be either any valid Postgres <code>Duration</code> supported by pg_partman, or an integer value. When it is a duration, partitions containing data greater than the duration will be dropped. When it is an integer value, any messages that have a <code>msg_id</code> less than <code>max(msg_id) - retention_interval</code> will be dropped. For example, if the max <code>msg_id</code> is 100 and the <code>retention_interval</code> is 60, any partitions with <code>msg_id</code> values less than 40 will be dropped. The value must agree with <code>partition_interval</code> (time based or numeric). The default is <code>'100000'</code>. Note: <code>retention_interval</code> does not apply to messages that have been deleted via <code>pgmq.delete()</code> or archived with <code>pgmq.archive()</code>. <code>pgmq.delete()</code> removes messages forever and <code>pgmq.archive()</code> moves messages to the corresponding archive table forever (for example, <code>a_my_queue</code>).</p>"},{"location":"partitioned-queues/#partition-maintenance","title":"Partition Maintenance","text":"<p>In order for automatic partition maintenance to take place, several settings must be added to the <code>postgresql.conf</code> file, which is typically located in the postgres <code>DATADIR</code>. <code>pg_partman_bgw.interval</code> in <code>postgresql.conf</code>. Below are the default configuration values set in pgmq docker images.</p> <p>Add the following to <code>postgresql.conf</code>. Note, changing <code>shared_preload_libraries</code> requires a restart of Postgres.</p> <p><code>pg_partman_bgw.interval</code> sets the interval at which <code>pg_partman</code> conducts maintenance. This creates new partitions and dropping of partitions falling out of the <code>retention_interval</code>. By default, <code>pg_partman</code> will keep 4 partitions \"ahead\" of the currently active partition.</p> <pre><code>shared_preload_libraries = 'pg_partman_bgw' # requires restart of Postgres\npg_partman_bgw.interval = 60\npg_partman_bgw.role = 'postgres'\npg_partman_bgw.dbname = 'postgres'\n</code></pre>"},{"location":"topics/","title":"Topic-Based Routing","text":"<p>PGMQ supports topic-based message routing with wildcard patterns, similar to AMQP topic exchanges. This feature allows you to route messages to multiple queues based on routing keys and pattern matching.</p>"},{"location":"topics/#overview","title":"Overview","text":"<p>Topic routing in PGMQ works by binding patterns to queues. When a message is sent with a routing key, it is delivered to all queues whose patterns match that key. This enables flexible publish-subscribe patterns and content-based routing.</p>"},{"location":"topics/#key-features","title":"Key Features","text":"<ul> <li>Wildcard patterns: Use <code>*</code> (one segment) and <code>#</code> (zero or more segments) for flexible matching</li> <li>Multiple queue delivery: A single message can be routed to multiple queues</li> <li>Pattern-based subscriptions: Queues subscribe to message types via patterns</li> <li>Dry-run testing: Test routing without sending messages using <code>test_routing()</code></li> <li>Precompiled regex: Patterns are compiled to regex at bind time for fast matching</li> <li>Automatic cleanup: Bindings are removed when queues are dropped (CASCADE)</li> </ul>"},{"location":"topics/#how-it-works","title":"How It Works","text":""},{"location":"topics/#routing-keys-and-patterns","title":"Routing Keys and Patterns","text":"<p>Routing keys and patterns use dot-separated segments:</p> <pre><code>-- Routing keys (used when sending messages)\n'logs.api.error'\n'orders.created'\n'user.signup.completed'\n\n-- Patterns (used when binding to queues)\n'logs.*'           -- Matches exactly one segment after 'logs.'\n'logs.#'           -- Matches zero or more segments after 'logs.'\n'*.error'          -- Matches any single segment before '.error'\n'#.error'          -- Matches zero or more segments before '.error'\n'logs.*.error'     -- Matches 'logs.{any}.error'\n</code></pre>"},{"location":"topics/#wildcards","title":"Wildcards","text":"Wildcard Meaning Example Pattern Matches Does Not Match <code>*</code> Exactly one segment <code>logs.*</code> <code>logs.error</code>, <code>logs.info</code> <code>logs</code>, <code>logs.api.error</code> <code>#</code> Zero or more segments <code>logs.#</code> <code>logs.error</code>, <code>logs.api.error</code> <code>logs</code> (no dot after)"},{"location":"topics/#binding-patterns-to-queues","title":"Binding Patterns to Queues","text":"<pre><code>-- Create queues\nSELECT pgmq.create('all_logs');\nSELECT pgmq.create('error_logs');\nSELECT pgmq.create('api_errors');\n\n-- Bind patterns\nSELECT pgmq.bind_topic('logs.#', 'all_logs'); -- All logs\nSELECT pgmq.bind_topic('logs.*.error', 'error_logs'); -- Error logs from any service\nSELECT pgmq.bind_topic('logs.api.error', 'api_errors'); -- Only API errors\n</code></pre>"},{"location":"topics/#sending-messages-with-routing-keys","title":"Sending Messages with Routing Keys","text":"<pre><code>-- This message routes to: all_logs, error_logs, api_errors (3 queues)\nSELECT pgmq.send_topic('logs.api.error', '{\"message\": \"API failed\"}');\n\n-- This message routes to: all_logs, error_logs (2 queues)\nSELECT pgmq.send_topic('logs.db.error', '{\"message\": \"DB connection failed\"}');\n\n-- This message routes to: all_logs only (1 queue)\nSELECT pgmq.send_topic('logs.api.info', '{\"message\": \"Request received\"}');\n</code></pre>"},{"location":"topics/#api-reference","title":"API Reference","text":""},{"location":"topics/#binding-functions","title":"Binding Functions","text":""},{"location":"topics/#pgmqbind_topicpattern-queue_name","title":"<code>pgmq.bind_topic(pattern, queue_name)</code>","text":"<p>Bind a pattern to a queue. Messages matching the pattern will be routed to this queue.</p> <p>Parameters:</p> <ul> <li><code>pattern</code> (text): The wildcard pattern to match routing keys</li> <li><code>queue_name</code> (text): Name of the queue to receive matching messages</li> </ul> <p>Returns: void</p> <p>Example:</p> <pre><code>SELECT pgmq.bind_topic('orders.#', 'order_events');\nSELECT pgmq.bind_topic('orders.*.failed', 'failed_orders');\n</code></pre> <p>Notes:</p> <ul> <li>Patterns are validated before binding</li> <li>Binding the same pattern to the same queue is idempotent (no error, no duplicate)</li> <li>One pattern can be bound to multiple queues</li> <li>One queue can have multiple pattern bindings</li> </ul>"},{"location":"topics/#pgmqunbind_topicpattern-queue_name","title":"<code>pgmq.unbind_topic(pattern, queue_name)</code>","text":"<p>Remove a pattern binding from a queue.</p> <p>Parameters:</p> <ul> <li><code>pattern</code> (text): The pattern to unbind</li> <li><code>queue_name</code> (text): Name of the queue</li> </ul> <p>Returns: boolean - <code>true</code> if a binding was removed, <code>false</code> if no binding existed</p> <p>Example:</p> <pre><code>SELECT pgmq.unbind_topic('orders.#', 'order_events');\n</code></pre>"},{"location":"topics/#pgmqlist_topic_bindings","title":"<code>pgmq.list_topic_bindings()</code>","text":"<p>Returns all topic bindings across all queues.</p> <p>Returns: Table with columns:</p> <ul> <li><code>pattern</code> (text): The wildcard pattern</li> <li><code>queue_name</code> (text): Name of the queue receiving matching messages</li> <li><code>bound_at</code> (timestamp with time zone): When the binding was created</li> <li><code>compiled_regex</code> (text): The internal regex used for matching</li> </ul> <p>Example:</p> <pre><code>SELECT * FROM pgmq.list_topic_bindings();\n-- Returns:\n--   pattern      | queue_name  | bound_at                   | compiled_regex\n--   -------------+-------------+----------------------------+-------------------\n--   orders.#     | all_orders  | 2024-01-15 10:30:00.000000 | ^orders\\..*$\n--   logs.*.error | error_logs  | 2024-01-15 10:29:00.000000 | ^logs\\.[^.]+\\.error$\n</code></pre> <p>Notes:</p> <ul> <li>Results are ordered by <code>bound_at</code> DESC (most recent first), then by <code>pattern</code> and <code>queue_name</code></li> <li>Use this to audit or debug your topic routing configuration</li> </ul>"},{"location":"topics/#pgmqlist_topic_bindingsqueue_name","title":"<code>pgmq.list_topic_bindings(queue_name)</code>","text":"<p>Returns all topic bindings for a specific queue.</p> <p>Parameters:</p> <ul> <li><code>queue_name</code> (text): Name of the queue</li> </ul> <p>Returns: Table with columns:</p> <ul> <li><code>pattern</code> (text): The wildcard pattern</li> <li><code>queue_name</code> (text): Name of the queue (always matches the parameter)</li> <li><code>bound_at</code> (timestamp with time zone): When the binding was created</li> <li><code>compiled_regex</code> (text): The internal regex used for matching</li> </ul> <p>Example:</p> <pre><code>SELECT * FROM pgmq.list_topic_bindings('order_events');\n-- Returns:\n--   pattern         | queue_name    | bound_at                   | compiled_regex\n--   ----------------+---------------+----------------------------+---------------------\n--   orders.#        | order_events  | 2024-01-15 10:30:00.000000 | ^orders\\..*$\n--   orders.*.failed | order_events  | 2024-01-15 10:28:00.000000 | ^orders\\.[^.]+\\.failed$\n</code></pre> <p>Notes:</p> <ul> <li>Results are ordered by <code>bound_at</code> DESC (most recent first), then by <code>pattern</code></li> <li>Returns empty result if queue has no bindings</li> <li><code>queue_name</code> column is included for consistency with the no-argument version</li> </ul>"},{"location":"topics/#sending-functions","title":"Sending Functions","text":""},{"location":"topics/#pgmqsend_topicrouting_key-msg-headers-delay","title":"<code>pgmq.send_topic(routing_key, msg, headers, delay)</code>","text":"<p>Send a message to all queues whose patterns match the routing key.</p> <p>Parameters:</p> <ul> <li><code>routing_key</code> (text): The routing key for pattern matching</li> <li><code>msg</code> (jsonb): The message payload</li> <li><code>headers</code> (jsonb): Optional message headers</li> <li><code>delay</code> (integer): Delay in seconds before message becomes visible</li> </ul> <p>Returns: integer - Number of queues the message was sent to</p> <p>Example:</p> <pre><code>-- Full signature\nSELECT pgmq.send_topic('orders.created', '{\"order_id\": 123}', '{\"priority\": \"high\"}', 0);\n\n-- Simplified versions\nSELECT pgmq.send_topic('orders.created', '{\"order_id\": 123}');\nSELECT pgmq.send_topic('orders.created', '{\"order_id\": 123}', 5); -- 5 second delay\n</code></pre> <p>Notes:</p> <ul> <li>If no patterns match the routing key, the message is not sent (returns 0)</li> <li>If multiple patterns match, the message is sent to all matching queues</li> <li>All sends succeed or all fail (transactional)</li> </ul>"},{"location":"topics/#pgmqsend_batch_topicrouting_key-msgs-headers-delay","title":"<code>pgmq.send_batch_topic(routing_key, msgs, headers, delay)</code>","text":"<p>Send multiple messages to all queues whose patterns match the routing key.</p> <p>Parameters:</p> <ul> <li><code>routing_key</code> (text): The routing key for pattern matching</li> <li><code>msgs</code> (jsonb[]): Array of message payloads to send</li> <li><code>headers</code> (jsonb[]): Optional array of headers for each message</li> <li><code>delay</code> (integer): Delay in seconds before messages become visible</li> <li><code>delay</code> (timestamp with time zone): Timestamp when messages become visible</li> </ul> <p>Returns: Table with columns: - <code>queue_name</code> (text): Name of the queue that received messages - <code>msg_id</code> (bigint): ID of each message that was sent</p> <p>Example:</p> <pre><code>-- Send 3 messages to all matching queues\nSELECT * FROM pgmq.send_batch_topic(\n    'orders.created',\n    ARRAY[\n        '{\"order_id\": 1, \"amount\": 100}',\n        '{\"order_id\": 2, \"amount\": 200}',\n        '{\"order_id\": 3, \"amount\": 300}'\n    ]::jsonb[]\n);\n\n-- Returns (if 2 queues match the pattern):\n--  queue_name       | msg_id\n-- ------------------+--------\n--  order_processor  | 1\n--  order_processor  | 2\n--  order_processor  | 3\n--  order_analytics  | 1\n--  order_analytics  | 2\n--  order_analytics  | 3\n\n-- With headers\nSELECT * FROM pgmq.send_batch_topic(\n    'notifications.email',\n    ARRAY['{\"to\": \"user1@example.com\"}', '{\"to\": \"user2@example.com\"}']::jsonb[],\n    ARRAY['{\"priority\": \"high\"}', '{\"priority\": \"normal\"}']::jsonb[]\n);\n\n-- Simplified versions\nSELECT * FROM pgmq.send_batch_topic('logs.info', ARRAY['{\"msg\": \"test\"}']::jsonb[]);\nSELECT * FROM pgmq.send_batch_topic('alerts.critical', ARRAY['{\"alert\": \"down\"}']::jsonb[], 60); -- 60 second delay\n\n-- With timestamp delay (visible in 1 hour)\nSELECT * FROM pgmq.send_batch_topic(\n    'scheduled.tasks',\n    ARRAY['{\"task\": \"backup\"}']::jsonb[],\n    CURRENT_TIMESTAMP + INTERVAL '1 hour'\n);\n</code></pre> <p>Notes:</p> <ul> <li>Each message in the batch is sent to all matching queues</li> <li>If the routing key matches 2 queues and you send 3 messages, you get 6 total messages (3 per queue)</li> <li>Headers array length must exactly match messages array length when provided (not NULL). Empty headers arrays will fail validation if msgs is not empty. To send without headers, omit the parameter or pass NULL</li> <li>If no patterns match the routing key, returns an empty result set</li> <li>All sends succeed or all fail (transactional)</li> </ul>"},{"location":"topics/#testing-functions","title":"Testing Functions","text":""},{"location":"topics/#pgmqtest_routingrouting_key","title":"<code>pgmq.test_routing(routing_key)</code>","text":"<p>Test which queues would receive a message with the given routing key, without actually sending a message.</p> <p>Parameters:</p> <ul> <li><code>routing_key</code> (text): The routing key to test</li> </ul> <p>Returns: Table with columns:</p> <ul> <li><code>pattern</code> (text): The matching pattern</li> <li><code>queue_name</code> (text): The queue that would receive the message</li> <li><code>compiled_regex</code> (text): The internal regex used for matching</li> </ul> <p>Example:</p> <pre><code>SELECT *\nFROM pgmq.test_routing('logs.api.error');\n-- Returns:\n--   pattern      | queue_name  | compiled_regex\n--   -------------+-------------+-------------------\n--   logs.#       | all_logs    | ^logs\\..*$\n--   logs.*.error | error_logs  | ^logs\\.[^.]+\\.error$\n</code></pre>"},{"location":"topics/#validation-functions","title":"Validation Functions","text":""},{"location":"topics/#pgmqvalidate_routing_keyrouting_key","title":"<code>pgmq.validate_routing_key(routing_key)</code>","text":"<p>Validate that a routing key is well-formed.</p> <p>Valid routing keys:</p> <ul> <li>Alphanumeric characters, dots, hyphens, and underscores</li> <li>Cannot start or end with a dot</li> <li>Cannot contain consecutive dots</li> <li>Cannot contain wildcards (<code>*</code> or <code>#</code>)</li> <li>Maximum 255 characters</li> </ul> <p>Example:</p> <pre><code>SELECT pgmq.validate_routing_key('logs.api.error'); -- Returns true\nSELECT pgmq.validate_routing_key('logs..error'); -- Raises exception\n</code></pre>"},{"location":"topics/#pgmqvalidate_topic_patternpattern","title":"<code>pgmq.validate_topic_pattern(pattern)</code>","text":"<p>Validate that a topic pattern is well-formed.</p> <p>Valid patterns:</p> <ul> <li>Same rules as routing keys, plus <code>*</code> and <code>#</code> wildcards</li> <li>Cannot have consecutive wildcards (<code>**</code>, <code>##</code>, <code>*#</code>, <code>#*</code>)</li> </ul> <p>Example:</p> <pre><code>SELECT pgmq.validate_topic_pattern('logs.*.error'); -- Returns true\nSELECT pgmq.validate_topic_pattern('logs.**'); -- Raises exception\n</code></pre>"},{"location":"topics/#usage-patterns","title":"Usage Patterns","text":""},{"location":"topics/#1-log-aggregation","title":"1. Log Aggregation","text":"<p>Route logs to different queues based on severity and service:</p> <pre><code>-- Create queues\nSELECT pgmq.create('logs_all');\nSELECT pgmq.create('logs_errors');\nSELECT pgmq.create('logs_critical');\nSELECT pgmq.create('api_logs');\n\n-- Bind patterns\nSELECT pgmq.bind_topic('#', 'logs_all'); -- All logs\nSELECT pgmq.bind_topic('*.error', 'logs_errors'); -- All errors\nSELECT pgmq.bind_topic('*.critical', 'logs_critical'); -- All critical\nSELECT pgmq.bind_topic('api.#', 'api_logs');\n-- API service logs\n\n-- Send logs\nSELECT pgmq.send_topic('api.error', '{\"msg\": \"API error\"}');\n-- Routes to: logs_all, logs_errors, api_logs\n\nSELECT pgmq.send_topic('db.critical', '{\"msg\": \"DB down\"}');\n-- Routes to: logs_all, logs_critical\n</code></pre>"},{"location":"topics/#2-event-broadcasting-fanout","title":"2. Event Broadcasting (Fanout)","text":"<p>Send events to all interested consumers:</p> <pre><code>-- Create consumer queues\nSELECT pgmq.create('notifications');\nSELECT pgmq.create('analytics');\nSELECT pgmq.create('audit_log');\n\n-- All queues subscribe to everything\nSELECT pgmq.bind_topic('#', 'notifications');\nSELECT pgmq.bind_topic('#', 'analytics');\nSELECT pgmq.bind_topic('#', 'audit_log');\n\n-- Any event goes to all queues\nSELECT pgmq.send_topic('user.signup', '{\"user_id\": 123}');\n-- Routes to all 3 queues\n</code></pre>"},{"location":"topics/#3-direct-routing-exact-match","title":"3. Direct Routing (Exact Match)","text":"<p>Route specific events to specific queues:</p> <pre><code>-- Create queues\nSELECT pgmq.create('user_events');\nSELECT pgmq.create('order_events');\n\n-- Bind exact patterns (no wildcards)\nSELECT pgmq.bind_topic('user.created', 'user_events');\nSELECT pgmq.bind_topic('user.updated', 'user_events');\nSELECT pgmq.bind_topic('user.deleted', 'user_events');\nSELECT pgmq.bind_topic('order.placed', 'order_events');\nSELECT pgmq.bind_topic('order.shipped', 'order_events');\n\n-- Messages route to exactly one queue\nSELECT pgmq.send_topic('user.created', '{\"user_id\": 1}');\n-- Routes to: user_events only\n</code></pre>"},{"location":"topics/#4-geographic-routing","title":"4. Geographic Routing","text":"<p>Route messages based on region:</p> <pre><code>-- Create regional queues\nSELECT pgmq.create('events_us');\nSELECT pgmq.create('events_eu');\nSELECT pgmq.create('events_global');\n\n-- Bind regional patterns\nSELECT pgmq.bind_topic('us.#', 'events_us');\nSELECT pgmq.bind_topic('eu.#', 'events_eu');\nSELECT pgmq.bind_topic('#', 'events_global');\n\n-- Route by region\nSELECT pgmq.send_topic('us.orders.created', '{\"order_id\": 100}');\n-- Routes to: events_us, events_global\n\nSELECT pgmq.send_topic('eu.users.signup', '{\"user_id\": 50}');\n-- Routes to: events_eu, events_global\n</code></pre>"},{"location":"topics/#5-multi-tenant-processing","title":"5. Multi-Tenant Processing","text":"<p>Route messages to tenant-specific and shared queues:</p> <pre><code>-- Create queues\nSELECT pgmq.create('tenant_acme');\nSELECT pgmq.create('tenant_globex');\nSELECT pgmq.create('all_tenants');\n\n-- Bind patterns\nSELECT pgmq.bind_topic('acme.#', 'tenant_acme');\nSELECT pgmq.bind_topic('globex.#', 'tenant_globex');\nSELECT pgmq.bind_topic('#', 'all_tenants');\n\n-- Route by tenant\nSELECT pgmq.send_topic('acme.orders.new', '{\"order\": \"data\"}');\n-- Routes to: tenant_acme, all_tenants\n</code></pre>"},{"location":"topics/#6-batch-message-publishing","title":"6. Batch Message Publishing","text":"<p>Send multiple messages at once using <code>send_batch_topic</code>:</p> <pre><code>-- Create notification queues\nSELECT pgmq.create('email_queue');\nSELECT pgmq.create('sms_queue');\nSELECT pgmq.create('all_notifications');\n\n-- Bind patterns\nSELECT pgmq.bind_topic('notify.email.#', 'email_queue');\nSELECT pgmq.bind_topic('notify.sms.#', 'sms_queue');\nSELECT pgmq.bind_topic('notify.#', 'all_notifications');\n\n-- Send batch of email notifications\nSELECT * FROM pgmq.send_batch_topic(\n    'notify.email.welcome',\n    ARRAY[\n        '{\"to\": \"user1@example.com\", \"name\": \"Alice\"}',\n        '{\"to\": \"user2@example.com\", \"name\": \"Bob\"}',\n        '{\"to\": \"user3@example.com\", \"name\": \"Carol\"}'\n    ]::jsonb[]\n);\n-- Routes 3 messages each to: email_queue and all_notifications (6 total messages)\n\n-- Send batch with headers for priority handling\nSELECT * FROM pgmq.send_batch_topic(\n    'notify.sms.alert',\n    ARRAY['{\"phone\": \"+1234567890\", \"msg\": \"Alert!\"}']::jsonb[],\n    ARRAY['{\"priority\": \"urgent\"}']::jsonb[]\n);\n-- Routes to: sms_queue and all_notifications with priority header\n\n-- Send batch with delay (e.g., scheduled notifications)\nSELECT * FROM pgmq.send_batch_topic(\n    'notify.email.reminder',\n    ARRAY[\n        '{\"to\": \"user@example.com\", \"subject\": \"Reminder\"}',\n        '{\"to\": \"admin@example.com\", \"subject\": \"Daily report\"}'\n    ]::jsonb[],\n    3600  -- Delay 1 hour\n);\n-- Messages become visible in 1 hour\n</code></pre>"},{"location":"topics/#performance-considerations","title":"Performance Considerations","text":""},{"location":"topics/#pattern-compilation","title":"Pattern Compilation","text":"<p>Patterns are compiled to regular expressions when bound, not at send time:</p> <pre><code>-- View all patterns with their compiled regex\nSELECT pattern, queue_name, compiled_regex\nFROM pgmq.list_topic_bindings();\n</code></pre> <p>This means:</p> <ul> <li>Binding is slightly slower (regex compilation)</li> <li>Sending is fast (uses precompiled regex)</li> <li>Many bindings = more patterns to check per send</li> </ul>"},{"location":"topics/#indexing","title":"Indexing","text":"<p>The <code>topic_bindings</code> table has a covering index for efficient pattern scanning:</p> <pre><code>-- Index includes queue_name for index-only scans\nCREATE INDEX idx_topic_bindings_covering\n    ON pgmq.topic_bindings (pattern) INCLUDE (queue_name);\n</code></pre>"},{"location":"topics/#examples","title":"Examples","text":"<p>See examples/topics.sql for comprehensive usage examples including:</p> <ul> <li>Wildcard differences (<code>*</code> vs <code>#</code>)</li> <li>Topic-based routing</li> <li>Fanout pattern (broadcast)</li> <li>Direct routing (exact match)</li> <li>Dry-run testing</li> </ul>"},{"location":"api/sql/functions/","title":"Functions","text":""},{"location":"api/sql/functions/#sending-messages","title":"Sending Messages","text":""},{"location":"api/sql/functions/#send","title":"send","text":"<p>Send a single message to a queue with optional headers and delay.</p> <p>Signatures:</p> <pre><code>pgmq.send(queue_name text, msg jsonb)\npgmq.send(queue_name text, msg jsonb, headers jsonb)\npgmq.send(queue_name text, msg jsonb, delay integer)\npgmq.send(queue_name text, msg jsonb, delay timestamp with time zone)\npgmq.send(queue_name text, msg jsonb, headers jsonb, delay integer)\npgmq.send(queue_name text, msg jsonb, headers jsonb, delay timestamp with time zone)\n\nRETURNS SETOF bigint\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msg jsonb The message to send to the queue headers jsonb Optional message headers/metadata delay integer Time in seconds before the message becomes visible delay timestamp with time zone Timestamp when the message becomes visible <p>Returns: The ID of the message that was added to the queue.</p> <p>Examples:</p> <pre><code>-- Send a message\nselect * from pgmq.send('my_queue', '{\"hello\": \"world\"}');\n send\n------\n    1\n\n-- Send a message with headers\nselect * from pgmq.send('my_queue', '{\"hello\": \"world\"}', '{\"trace_id\": \"abc123\"}');\n send\n------\n    2\n\n-- Message with a delay of 5 seconds\nselect * from pgmq.send('my_queue', '{\"hello\": \"world\"}', 5);\n send\n------\n    3\n\n-- Message readable from tomorrow\nselect * from pgmq.send('my_queue', '{\"hello\": \"world\"}', CURRENT_TIMESTAMP + INTERVAL '1 day');\n send\n------\n    4\n\n-- Message with headers and delay\nselect * from pgmq.send('my_queue', '{\"hello\": \"world\"}', '{\"priority\": \"high\"}', 10);\n send\n------\n    5\n</code></pre>"},{"location":"api/sql/functions/#send_batch","title":"send_batch","text":"<p>Send 1 or more messages to a queue with optional headers and delay.</p> <p>Signatures:</p> <pre><code>pgmq.send_batch(queue_name text, msgs jsonb[])\npgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[])\npgmq.send_batch(queue_name text, msgs jsonb[], delay integer)\npgmq.send_batch(queue_name text, msgs jsonb[], delay timestamp with time zone)\npgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[], delay integer)\npgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[], delay timestamp with time zone)\n\nRETURNS SETOF bigint\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msgs jsonb[] Array of messages to send to the queue headers jsonb[] Array of headers for each message (must match msgs length, or can be omitted) delay integer Time in seconds before the messages become visible delay timestamp with time zone Timestamp when the messages become visible <p>Returns: The IDs of the messages that were added to the queue.</p> <p>Validation: When <code>headers</code> is provided (not NULL), its array length must exactly match the length of <code>msgs</code>. This includes empty arrays - an empty headers array (e.g., <code>ARRAY[]::jsonb[]</code>) will fail validation if <code>msgs</code> is not empty. To send messages without headers, either omit the <code>headers</code> parameter or pass NULL.</p> <p>Examples:</p> <pre><code>-- Send multiple messages\nselect * from pgmq.send_batch('my_queue',\n    ARRAY[\n        '{\"hello\": \"world_0\"}',\n        '{\"hello\": \"world_1\"}'\n    ]::jsonb[]\n);\n send_batch\n------------\n          1\n          2\n\n-- Send with headers for each message\nselect * from pgmq.send_batch('my_queue',\n    ARRAY['{\"hello\": \"world_0\"}', '{\"hello\": \"world_1\"}']::jsonb[],\n    ARRAY['{\"trace_id\": \"abc\"}', '{\"trace_id\": \"def\"}']::jsonb[]\n);\n send_batch\n------------\n          3\n          4\n\n-- Messages with a delay of 5 seconds\nselect * from pgmq.send_batch('my_queue',\n    ARRAY[\n        '{\"hello\": \"world_0\"}',\n        '{\"hello\": \"world_1\"}'\n    ]::jsonb[],\n    5\n);\n send_batch\n------------\n          5\n          6\n\n-- Messages readable from tomorrow\nselect * from pgmq.send_batch('my_queue',\n    ARRAY[\n        '{\"hello\": \"world_0\"}',\n        '{\"hello\": \"world_1\"}'\n    ]::jsonb[],\n    CURRENT_TIMESTAMP + INTERVAL '1 day'\n);\n send_batch\n------------\n          7\n          8\n</code></pre>"},{"location":"api/sql/functions/#topic-based-routing","title":"Topic-Based Routing","text":"<p>PGMQ supports topic-based message routing with wildcard patterns. Messages can be routed to multiple queues based on routing keys and pattern matching. See the Topics guide for detailed information.</p>"},{"location":"api/sql/functions/#send_topic","title":"send_topic","text":"<p>Send a message to all queues whose patterns match the routing key.</p> <p>Signatures:</p> <pre><code>pgmq.send_topic(routing_key text, msg jsonb)\npgmq.send_topic(routing_key text, msg jsonb, delay integer)\npgmq.send_topic(routing_key text, msg jsonb, headers jsonb, delay integer)\n\nRETURNS integer\n</code></pre> <p>Parameters:</p> Parameter Type Description routing_key text The routing key for pattern matching msg jsonb The message payload headers jsonb Optional message headers/metadata delay integer Time in seconds before the message becomes visible <p>Returns: The number of queues the message was sent to.</p> <p>Examples:</p> <pre><code>-- Create queues and bind patterns\nselect pgmq.create('logs_all');\nselect pgmq.create('logs_errors');\nselect pgmq.bind_topic('logs.#', 'logs_all');\nselect pgmq.bind_topic('logs.*.error', 'logs_errors');\n\n-- Send to matching queues\nselect pgmq.send_topic('logs.api.error', '{\"message\": \"API failed\"}');\n send_topic\n------------\n          2\n-- Message sent to 2 queues: logs_all and logs_errors\n\n-- With headers\nselect pgmq.send_topic('logs.db.error', '{\"message\": \"DB error\"}', '{\"severity\": \"high\"}', 0);\n\n-- With delay\nselect pgmq.send_topic('logs.api.info', '{\"message\": \"Request received\"}', 5);\n</code></pre>"},{"location":"api/sql/functions/#send_batch_topic","title":"send_batch_topic","text":"<p>Send multiple messages to all queues whose patterns match the routing key.</p> <p>Signatures:</p> <pre><code>pgmq.send_batch_topic(routing_key text, msgs jsonb[])\npgmq.send_batch_topic(routing_key text, msgs jsonb[], headers jsonb[])\npgmq.send_batch_topic(routing_key text, msgs jsonb[], delay integer)\npgmq.send_batch_topic(routing_key text, msgs jsonb[], delay timestamp with time zone)\npgmq.send_batch_topic(routing_key text, msgs jsonb[], headers jsonb[], delay integer)\npgmq.send_batch_topic(routing_key text, msgs jsonb[], headers jsonb[], delay timestamp with time zone)\n\nRETURNS TABLE(queue_name text, msg_id bigint)\n</code></pre> <p>Parameters:</p> Parameter Type Description routing_key text The routing key for pattern matching msgs jsonb[] Array of message payloads to send headers jsonb[] Optional array of headers for each message delay integer Time in seconds before the messages become visible delay timestamp with time zone Timestamp when the messages become visible <p>Returns: A table with the queue name and message ID for each message sent.</p> <p>Validation: When <code>headers</code> is provided (not NULL), its array length must exactly match the length of <code>msgs</code>. Empty headers arrays will fail validation if <code>msgs</code> is not empty. To send messages without headers, either omit the <code>headers</code> parameter or pass NULL.</p> <p>Examples:</p> <pre><code>-- Send batch of messages to matching queues\nselect * from pgmq.send_batch_topic(\n    'orders.created',\n    array[\n        '{\"order_id\": 1, \"amount\": 100}',\n        '{\"order_id\": 2, \"amount\": 200}'\n    ]::jsonb[]\n);\n      queue_name       | msg_id\n-----------------------+--------\n order_processor       |      1\n order_processor       |      2\n order_analytics       |      1\n order_analytics       |      2\n-- Each message sent to all matching queues\n\n-- With headers\nselect * from pgmq.send_batch_topic(\n    'notifications.email',\n    array['{\"to\": \"user1@example.com\"}', '{\"to\": \"user2@example.com\"}']::jsonb[],\n    array['{\"priority\": \"high\"}', '{\"priority\": \"normal\"}']::jsonb[]\n);\n\n-- With delay (messages visible in 60 seconds)\nselect * from pgmq.send_batch_topic(\n    'alerts.critical',\n    array['{\"alert\": \"system down\"}']::jsonb[],\n    60\n);\n\n-- With timestamp delay (visible in 1 hour)\nselect * from pgmq.send_batch_topic(\n    'scheduled.tasks',\n    array['{\"task\": \"backup\"}']::jsonb[],\n    CURRENT_TIMESTAMP + INTERVAL '1 hour'\n);\n</code></pre>"},{"location":"api/sql/functions/#bind_topic","title":"bind_topic","text":"<p>Bind a pattern to a queue. Messages with routing keys matching the pattern will be routed to this queue.</p> <p>Signature:</p> <pre><code>pgmq.bind_topic(pattern text, queue_name text)\n\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description pattern text The wildcard pattern to match routing keys queue_name text Name of the queue to receive matching messages <p>Wildcard patterns: - <code>*</code> matches exactly one segment (e.g., <code>logs.*</code> matches <code>logs.error</code> but not <code>logs.api.error</code>) - <code>#</code> matches zero or more segments (e.g., <code>logs.#</code> matches <code>logs.error</code> and <code>logs.api.error</code>)</p> <p>Examples:</p> <pre><code>-- Create queue\nselect pgmq.create('error_logs');\n\n-- Bind patterns\nselect pgmq.bind_topic('logs.*.error', 'error_logs');  -- Errors from any service\nselect pgmq.bind_topic('alerts.#', 'error_logs');      -- All alerts\n\n-- Binding is idempotent\nselect pgmq.bind_topic('logs.*.error', 'error_logs');  -- No error, no duplicate\n</code></pre>"},{"location":"api/sql/functions/#unbind_topic","title":"unbind_topic","text":"<p>Remove a pattern binding from a queue.</p> <p>Signature:</p> <pre><code>pgmq.unbind_topic(pattern text, queue_name text)\n\nRETURNS boolean\n</code></pre> <p>Parameters:</p> Parameter Type Description pattern text The pattern to unbind queue_name text Name of the queue <p>Returns: <code>true</code> if a binding was removed, <code>false</code> if no binding existed.</p> <p>Examples:</p> <pre><code>-- Remove binding\nselect pgmq.unbind_topic('logs.*.error', 'error_logs');\n unbind_topic\n--------------\n t\n\n-- No binding to remove\nselect pgmq.unbind_topic('nonexistent.pattern', 'error_logs');\n unbind_topic\n--------------\n f\n</code></pre>"},{"location":"api/sql/functions/#test_routing","title":"test_routing","text":"<p>Test which queues would receive a message with the given routing key, without actually sending a message.</p> <p>Signature:</p> <pre><code>pgmq.test_routing(routing_key text)\n\nRETURNS TABLE(pattern text, queue_name text, compiled_regex text)\n</code></pre> <p>Parameters:</p> Parameter Type Description routing_key text The routing key to test <p>Returns: Table showing all patterns that match the routing key and which queues they route to.</p> <p>Examples:</p> <pre><code>-- Test routing\nselect * from pgmq.test_routing('logs.api.error');\n    pattern     |  queue_name  | compiled_regex\n----------------+--------------+---------------------------\n logs.#         | logs_all     | ^logs\\..*$\n logs.*.error   | error_logs   | ^logs\\.[^.]+\\.error$\n</code></pre>"},{"location":"api/sql/functions/#reading-messages","title":"Reading Messages","text":""},{"location":"api/sql/functions/#read","title":"read","text":"<p>Read 1 or more messages from a queue. The VT specifies the amount of time in seconds that the message will be invisible to other consumers after reading.</p> <pre>\n <code>\npgmq.read(\n    queue_name text,\n    vt integer,\n    qty integer,\n    conditional jsonb DEFAULT '{}')\n\nRETURNS SETOF pgmq.message_record\n </code>\n</pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue conditional jsonb Filters the messages by their json content. Defaults to '{}' - no filtering. This feature is experimental, and the API is subject to change in future releases <p>Examples:</p> <p>Read messages from a queue</p> <pre><code>select * from pgmq.read('my_queue', 10, 2);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |       message        | headers \n--------+---------+-------------------------------+-------------------------------+-------------------------------+----------------------+---------\n      1 |       1 | 2026-01-23 20:07:48.083773-06 | 2026-01-23 20:08:04.085665-06 | 2026-01-23 20:08:14.085665-06 | {\"hello\": \"world_0\"} | \n      2 |       1 | 2026-01-23 20:07:48.083773-06 | 2026-01-23 20:08:04.08568-06  | 2026-01-23 20:08:14.08568-06  | {\"hello\": \"world_1\"} | \n(2 rows)\n</code></pre> <p>Read a message from a queue with message filtering</p> <pre><code>select * from pgmq.read('my_queue', 10, 2, '{\"hello\": \"world_1\"}');\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |       message        |       headers       \n--------+---------+-------------------------------+-------------------------------+-------------------------------+----------------------+---------------------\n      2 |       2 | 2026-01-23 20:07:48.083773-06 | 2026-01-23 20:08:30.829749-06 | 2026-01-23 20:08:40.829749-06 | {\"hello\": \"world_1\"} | \n      4 |       1 | 2026-01-23 20:07:50.824379-06 | 2026-01-23 20:08:30.829765-06 | 2026-01-23 20:08:40.829765-06 | {\"hello\": \"world_1\"} | {\"trace_id\": \"def\"}\n(2 rows)\n</code></pre>"},{"location":"api/sql/functions/#read_with_poll","title":"read_with_poll","text":"<p>Same as read(). Also provides convenient long-poll functionality.  When there are no messages in the queue, the function call will wait for <code>max_poll_seconds</code> in duration before returning.  If messages reach the queue during that duration, they will be read and returned immediately.</p> <pre>\n <code>\n pgmq.read_with_poll(\n    queue_name text,\n    vt integer,\n    qty integer,\n    max_poll_seconds integer DEFAULT 5,\n    poll_interval_ms integer DEFAULT 100,\n    conditional jsonb DEFAULT '{}'\n)\nRETURNS SETOF pgmq.message_record\n </code>\n</pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. conditional jsonb Filters the messages by their json content. Defaults to '{}' - no filtering. This feature is experimental, and the API is subject to change in future releases <p>Example:</p> <pre><code>\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |       message        | headers \n--------+---------+-------------------------------+-------------------------------+-------------------------------+----------------------+---------\n      1 |       2 | 2026-01-23 20:07:48.083773-06 | 2026-01-23 20:09:09.588292-06 | 2026-01-23 20:09:10.588292-06 | {\"hello\": \"world_0\"} | \n(1 row)\n</code></pre>"},{"location":"api/sql/functions/#read_grouped","title":"read_grouped","text":"<p>Read messages from a queue with AWS SQS FIFO-style batch retrieval behavior. This function attempts to return as many messages as possible from the same message group, filling the batch from the earliest available group first. Messages with the same FIFO group ID (specified in the <code>x-pgmq-group</code> header) will be processed in order. Messages without FIFO headers are treated as belonging to a default group.</p> <pre>\n <code>\npgmq.read_grouped(\n    queue_name text,\n    vt integer,\n    qty integer\n)\nRETURNS SETOF pgmq.message_record\n </code>\n</pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue <p>FIFO Behavior (Fill from same group): - Messages with the same <code>x-pgmq-group</code> header value are processed in strict order - Only the oldest unprocessed message from each FIFO group can be read - The batch is filled preferentially from the earliest group (by oldest msg_id) - Messages from different FIFO groups can be processed in parallel - Messages without FIFO headers are treated as a single default group</p> <p>Examples:</p> <p>Send messages with FIFO grouping:</p> <pre><code>-- Send messages to the same FIFO group\nselect pgmq.send('my_queue', msg=&gt;'{\"order\": 1}', headers=&gt;'{\"x-pgmq-group\": \"user123\"}');\nselect pgmq.send('my_queue', msg=&gt;'{\"order\": 2}', headers=&gt;'{\"x-pgmq-group\": \"user123\"}');\nselect pgmq.send('my_queue', msg=&gt;'{\"order\": 3}', headers=&gt;'{\"x-pgmq-group\": \"user123\"}');\nselect pgmq.send('my_queue', msg=&gt;'{\"order\": 1}', headers=&gt;'{\"x-pgmq-group\": \"user456\"}');\n\n-- Read with FIFO grouped ordering - tries to fill batch from earliest group\nselect * from pgmq.read_grouped('my_queue', 10, 5);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |   message    |           headers           \n--------+---------+-------------------------------+-------------------------------+-------------------------------+--------------+-----------------------------\n      1 |       2 | 2026-01-23 20:10:17.015888-06 | 2026-01-23 20:13:22.965962-06 | 2026-01-23 20:13:32.965962-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user123\"}\n      2 |       2 | 2026-01-23 20:11:15.841062-06 | 2026-01-23 20:13:22.965977-06 | 2026-01-23 20:13:32.965977-06 | {\"order\": 2} | {\"x-pgmq-group\": \"user123\"}\n      3 |       2 | 2026-01-23 20:11:18.718345-06 | 2026-01-23 20:13:22.96598-06  | 2026-01-23 20:13:32.96598-06  | {\"order\": 3} | {\"x-pgmq-group\": \"user123\"}\n      4 |       2 | 2026-01-23 20:11:21.338077-06 | 2026-01-23 20:13:22.965982-06 | 2026-01-23 20:13:32.965982-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user456\"}\n</code></pre>"},{"location":"api/sql/functions/#read_grouped_with_poll","title":"read_grouped_with_poll","text":"<p>Same as read_grouped(). Also provides convenient long-poll functionality for FIFO queues.  When there are no messages available that respect FIFO ordering, the function call will wait for <code>max_poll_seconds</code> in duration before returning.</p> <pre>\n <code>\n pgmq.read_grouped_with_poll(\n    queue_name text,\n    vt integer,\n    qty integer,\n    max_poll_seconds integer DEFAULT 5,\n    poll_interval_ms integer DEFAULT 100\n)\nRETURNS SETOF pgmq.message_record\n </code>\n</pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue. max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. <p>Example:</p> <pre><code> select * from pgmq.read_grouped_with_poll('my_queue', 10, 1, 5, 100);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |   message    |           headers           \n--------+---------+-------------------------------+-------------------------------+-------------------------------+--------------+-----------------------------\n      1 |       5 | 2026-01-23 20:10:17.015888-06 | 2026-01-23 20:15:43.446826-06 | 2026-01-23 20:15:53.446826-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user123\"}\n(1 row)\n</code></pre>"},{"location":"api/sql/functions/#read_grouped_rr","title":"read_grouped_rr","text":"<p>Read messages from a queue while respecting FIFO (First-In-First-Out) ordering within message groups and using round-robin interleaving across groups. Messages with the same FIFO group ID (specified in the <code>x-pgmq-group</code> header) will be processed in strict order. Messages without FIFO headers are treated as belonging to a default group.</p> <pre>\n <code>\npgmq.read_grouped_rr(\n    queue_name text,\n    vt integer,\n    qty integer\n)\nRETURNS SETOF pgmq.message_record\n </code>\n</pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue <p>FIFO Behavior (Round Robin across groups): - Messages with the same <code>x-pgmq-group</code> header value are processed in strict order - Only the oldest unprocessed message from each FIFO group can be read - Messages from different FIFO groups can be processed in parallel - Messages without FIFO headers are treated as a single default group</p> <p>Examples:</p> <p>Send messages with FIFO grouping:</p> <pre><code>-- Send messages to the same FIFO group\nselect pgmq.send('my_queue', msg=&gt;'{\"order\": 1}', headers=&gt;'{\"x-pgmq-group\": \"user123\"}');\nselect pgmq.send('my_queue', msg=&gt;'{\"order\": 2}', headers=&gt;'{\"x-pgmq-group\": \"user123\"}');\nselect pgmq.send('my_queue', msg=&gt;'{\"order\": 1}', headers=&gt;'{\"x-pgmq-group\": \"user456\"}');\n\n-- Read with FIFO RR ordering - interleaves by group layers\nselect * from pgmq.read_grouped_rr('my_queue', 10, 5);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |   message    |           headers           \n--------+---------+-------------------------------+-------------------------------+-------------------------------+--------------+-----------------------------\n      1 |       1 | 2026-01-23 20:17:53.298176-06 | 2026-01-23 20:18:01.152451-06 | 2026-01-23 20:18:11.152451-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user123\"}\n      3 |       1 | 2026-01-23 20:17:53.302222-06 | 2026-01-23 20:18:01.152471-06 | 2026-01-23 20:18:11.152471-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user456\"}\n      2 |       1 | 2026-01-23 20:17:53.300656-06 | 2026-01-23 20:18:01.152468-06 | 2026-01-23 20:18:11.152468-06 | {\"order\": 2} | {\"x-pgmq-group\": \"user123\"}\n(3 rows)\n</code></pre>"},{"location":"api/sql/functions/#read_grouped_rr_with_poll","title":"read_grouped_rr_with_poll","text":"<p>Same as read_grouped_rr(). Also provides convenient long-poll functionality for FIFO queues.  When there are no messages available that respect FIFO ordering, the function call will wait for <code>max_poll_seconds</code> in duration before returning.</p> <pre>\n <code>\n pgmq.read_grouped_rr_with_poll(\n    queue_name text,\n    vt integer,\n    qty integer,\n    max_poll_seconds integer DEFAULT 5,\n    poll_interval_ms integer DEFAULT 100\n)\nRETURNS SETOF pgmq.message_record\n </code>\n</pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue. max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. <p>Example:</p> <pre><code>select * from pgmq.read_grouped_rr_with_poll('my_queue', 10, 1, 5, 100);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |   message    |           headers           \n--------+---------+-------------------------------+-------------------------------+-------------------------------+--------------+-----------------------------\n      1 |       2 | 2026-01-23 20:17:53.298176-06 | 2026-01-23 20:18:35.678351-06 | 2026-01-23 20:18:45.678351-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user123\"}\n</code></pre>"},{"location":"api/sql/functions/#pop","title":"pop","text":"<p>Reads one or more messages from a queue and deletes them upon read.</p> <p>Note: utilization of pop() results in at-most-once delivery semantics if the consuming application does not guarantee processing of the message.</p> <pre>\n <code>\npgmq.pop(queue_name text, qty integer DEFAULT 1)\nRETURNS SETOF pgmq.message_record\n </code>\n</pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue qty integer The number of messages to pop from the queue. Defaults to 1. <p>Example:</p> <pre><code>pgmq=# select * from pgmq.pop('my_queue');\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |   message    |           headers           \n--------+---------+-------------------------------+-------------------------------+-------------------------------+--------------+-----------------------------\n      1 |       2 | 2026-01-23 20:17:53.298176-06 | 2026-01-23 20:18:35.678351-06 | 2026-01-23 20:18:45.678351-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user123\"}\n</code></pre>"},{"location":"api/sql/functions/#deletingarchiving-messages","title":"Deleting/Archiving Messages","text":""},{"location":"api/sql/functions/#delete-single","title":"delete (single)","text":"<p>Deletes a single message from a queue.</p> <pre><code>pgmq.delete (queue_name text, msg_id: bigint)\nRETURNS boolean\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msg_id bigint Message ID of the message to delete <p>Example:</p> <pre><code>select pgmq.delete('my_queue', 5);\n delete\n--------\n t\n</code></pre>"},{"location":"api/sql/functions/#delete-batch","title":"delete (batch)","text":"<p>Delete one or many messages from a queue.</p> <pre><code>pgmq.delete (queue_name text, msg_ids: bigint[])\nRETURNS SETOF bigint\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to delete <p>Examples:</p> <p>Delete two messages that exist.</p> <pre><code>select * from pgmq.delete('my_queue', ARRAY[2, 3]);\n delete\n--------\n      2\n      3\n</code></pre> <p>Delete two messages, one that exists and one that does not. Message <code>999</code> does not exist.</p> <pre><code>select * from pgmq.delete('my_queue', ARRAY[6, 999]);\n delete\n--------\n      6\n</code></pre>"},{"location":"api/sql/functions/#purge_queue","title":"purge_queue","text":"<p>Permanently deletes all messages in a queue. Returns the number of messages that were deleted.</p> <pre><code>pgmq.purge_queue(queue_name text)\nRETURNS bigint\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue <p>Example:</p> <p>Purge the queue when it contains 8 messages;</p> <pre><code>select * from pgmq.purge_queue('my_queue');\n purge_queue\n-------------\n           8\n</code></pre>"},{"location":"api/sql/functions/#archive-single","title":"archive (single)","text":"<p>Removes a single requested message from the specified queue and inserts it into the queue's archive.</p> <pre><code>pgmq.archive(queue_name text, msg_id bigint)\nRETURNS boolean\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msg_id bigint Message ID of the message to archive <p>Returns: Boolean value indicating success or failure of the operation.</p> <p>Note: Archived messages are stored in the archive table with an additional <code>archived_at</code> timestamp field indicating when the message was archived.</p> <p>Example; remove message with ID 1 from queue <code>my_queue</code> and archive it:</p> <pre><code>SELECT * FROM pgmq.archive('my_queue', 1);\n archive\n---------\n       t\n</code></pre>"},{"location":"api/sql/functions/#archive-batch","title":"archive (batch)","text":"<p>Deletes a batch of requested messages from the specified queue and inserts them into the queue's archive.  Returns an ARRAY of message ids that were successfully archived.</p> <pre><code>pgmq.archive(queue_name text, msg_ids bigint[])\nRETURNS SETOF bigint\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to archive <p>Examples:</p> <p>Delete messages with ID 1 and 2 from queue <code>my_queue</code> and move to the archive.</p> <pre><code>SELECT * FROM pgmq.archive('my_queue', ARRAY[1, 2]);\n archive\n---------\n       1\n       2\n</code></pre> <p>Delete messages 4, which exists and 999, which does not exist.</p> <pre><code>select * from pgmq.archive('my_queue', ARRAY[4, 999]);\n archive\n---------\n       4\n</code></pre>"},{"location":"api/sql/functions/#queue-management","title":"Queue Management","text":""},{"location":"api/sql/functions/#create","title":"create","text":"<p>Create a new queue.</p> <pre><code>pgmq.create(queue_name text)\nRETURNS VOID\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue (max 47 characters) <p>Example:</p> <pre><code>select from pgmq.create('my_queue');\n create\n--------\n</code></pre>"},{"location":"api/sql/functions/#create_non_partitioned","title":"create_non_partitioned","text":"<p>Create a non-partitioned queue. This is the same as <code>create()</code>, but more explicit about the queue type.</p> <pre><code>pgmq.create_non_partitioned(queue_name text)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue (max 47 characters) <p>Example:</p> <pre><code>select from pgmq.create_non_partitioned('my_queue');\n create_non_partitioned\n------------------------\n</code></pre>"},{"location":"api/sql/functions/#create_partitioned","title":"create_partitioned","text":"<p>Create a partitioned queue. Requires the <code>pg_partman</code> extension to be installed.</p> <pre><code>pgmq.create_partitioned (\n    queue_name text,\n    partition_interval text DEFAULT '10000'::text,\n    retention_interval text DEFAULT '100000'::text\n)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue (max 47 characters) partition_interval text Partition size - numeric value for msg_id-based partitioning (e.g., '10000'), or time interval for timestamp-based partitioning (e.g., '1 day'). Defaults to '10000'. retention_interval text How long/how many messages to retain before deleting old partitions. Same format as partition_interval. Defaults to '100000'. <p>Example:</p> <p>Create a queue with 100,000 messages per partition, and will retain 10,000,000 messages on old partitions. Partitions greater than this will be deleted.</p> <pre><code>select from pgmq.create_partitioned(\n    'my_partitioned_queue',\n    '100000',\n    '10000000'\n);\n create_partitioned\n--------------------\n</code></pre>"},{"location":"api/sql/functions/#create_unlogged","title":"create_unlogged","text":"<p>Creates an unlogged table. This is useful when write throughput is more important that durability. See Postgres documentation for unlogged tables for more information.</p> <pre><code>pgmq.create_unlogged(queue_name text)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue <p>Example:</p> <pre><code>select pgmq.create_unlogged('my_unlogged');\n create_unlogged\n-----------------\n</code></pre>"},{"location":"api/sql/functions/#convert_archive_partitioned","title":"convert_archive_partitioned","text":"<p>Convert an existing non-partitioned archive table to a partitioned one. Requires the <code>pg_partman</code> extension to be installed. This is useful for migrating queues to partitioned archives after they have been created.</p> <pre><code>pgmq.convert_archive_partitioned(\n    table_name text,\n    partition_interval text DEFAULT '10000'::text,\n    retention_interval text DEFAULT '100000'::text,\n    leading_partition integer DEFAULT 10\n)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description table_name text The name of the queue whose archive should be partitioned partition_interval text Partition size - numeric value for msg_id-based partitioning (e.g., '10000'), or time interval for timestamp-based partitioning (e.g., '1 day'). Defaults to '10000'. retention_interval text How long/how many messages to retain before deleting old partitions. Same format as partition_interval. Defaults to '100000'. leading_partition integer Number of partitions to create in advance. Defaults to 10. <p>Note: This function renames the existing archive table to <code>&lt;table_name&gt;_old</code> and creates a new partitioned table. You may need to migrate data from the old table to the new one.</p> <p>Example:</p> <pre><code>select from pgmq.convert_archive_partitioned('my_queue', '10000', '100000');\n convert_archive_partitioned\n-----------------------------\n</code></pre>"},{"location":"api/sql/functions/#detach_archive","title":"detach_archive","text":"<p>\u26a0\ufe0f DEPRECATED: This function is deprecated and is now a no-op (does nothing). It will be removed in PGMQ v2.0. Archive tables are no longer member objects of the extension.</p> <p>Drop the queue's archive table as a member of the PGMQ extension. Useful for preventing the queue's archive table from being drop when <code>DROP EXTENSION pgmq</code> is executed.  This does not prevent the further archives() from appending to the archive table.</p> <pre><code>pgmq.detach_archive(queue_name text)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue <p>Example:</p> <pre><code>select * from pgmq.detach_archive('my_queue');\n detach_archive\n----------------\n</code></pre>"},{"location":"api/sql/functions/#drop_queue","title":"drop_queue","text":"<p>Deletes a queue and its archive table.</p> <pre><code>pgmq.drop_queue(queue_name text)\nRETURNS boolean\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue <p>Note: There is a deprecated 2-parameter version <code>drop_queue(queue_name, partitioned)</code> that will be removed in PGMQ v2.0. Use the single-parameter version instead, which automatically detects whether the queue is partitioned.</p> <p>Example:</p> <pre><code>select * from pgmq.drop_queue('my_unlogged');\n drop_queue\n------------\n t\n</code></pre>"},{"location":"api/sql/functions/#utilities","title":"Utilities","text":""},{"location":"api/sql/functions/#set_vt-single","title":"set_vt (single)","text":"<p>Sets the visibility timeout of a message to a specified time duration in the future. Returns the record of the message that was updated.</p> <pre><code>pgmq.set_vt(queue_name text, msg_id bigint, vt integer)\npgmq.set_vt(queue_name text, msg_id bigint, vt timestamp with time zone)\n\nRETURNS SETOF pgmq.message_record\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msg_id bigint ID of the message to set visibility time vt integer Duration from now, in seconds, that the message's VT should be set to vt timestamp with time zone Timestamp when the message becomes visible <p>Example:</p> <p>Set the visibility timeout of message 1 to 30 seconds from now.</p> <pre><code>select * from pgmq.set_vt('my_queue', 1, 30);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |   message    |           headers           \n--------+---------+-------------------------------+-------------------------------+-------------------------------+--------------+-----------------------------\n      1 |       1 | 2026-01-23 20:17:53.300656-06 | 2026-01-23 20:18:01.152468-06 | 2026-01-23 20:24:49.398759-06 | {\"order\": 2} | {\"x-pgmq-group\": \"user123\"}\n</code></pre>"},{"location":"api/sql/functions/#set_vt-batch","title":"set_vt (batch)","text":"<p>Sets the visibility timeout of multiple messages to a specified time duration in the future. Returns the records of the messages that were updated.</p> <pre><code>pgmq.set_vt(queue_name text, msg_ids bigint[], vt integer)\npgmq.set_vt(queue_name text, msg_ids bigint[], vt timestamp with time zone)\n\nRETURNS SETOF pgmq.message_record\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to set visibility time vt integer Duration from now, in seconds, that the messages' VT should be set to vt timestamp with time zone Timestamp when the messages become visible <p>Example:</p> <p>Set the visibility timeout of messages 1 and 2 to 60 seconds from now.</p> <pre><code>select * from pgmq.set_vt('my_queue', ARRAY[1, 2], 60);\n</code></pre> <pre><code> msg_id | read_ct |          enqueued_at          |         last_read_at          |              vt               |   message    |           headers           \n--------+---------+-------------------------------+-------------------------------+-------------------------------+--------------+-----------------------------\n      1 |       1 | 2026-01-23 20:17:53.302222-06 | 2026-01-23 20:18:01.152471-06 | 2026-01-23 20:25:53.789922-06 | {\"order\": 1} | {\"x-pgmq-group\": \"user456\"}\n      2 |       1 | 2026-01-23 20:17:53.300656-06 | 2026-01-23 20:18:01.152468-06 | 2026-01-23 20:25:53.789922-06 | {\"order\": 2} | {\"x-pgmq-group\": \"user123\"}\n</code></pre>"},{"location":"api/sql/functions/#list_queues","title":"list_queues","text":"<p>List all the queues that currently exist.</p> <pre><code>pgmq.list_queues()\nRETURNS SETOF pgmq.queue_record\n</code></pre> <p>Example:</p> <pre><code>select * from pgmq.list_queues();\n      queue_name      |          created_at           | is_partitioned | is_unlogged\n----------------------+-------------------------------+----------------+-------------\n my_queue             | 2023-10-28 14:13:17.092576-05 | f              | f\n my_partitioned_queue | 2023-10-28 19:47:37.098692-05 | t              | f\n my_unlogged          | 2023-10-28 20:02:30.976109-05 | f              | t\n</code></pre>"},{"location":"api/sql/functions/#metrics","title":"metrics","text":"<p>Get metrics for a specific queue.</p> <pre><code>pgmq.metrics(queue_name text)\nRETURNS pgmq.metrics_result\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue <p>Returns:</p> Attribute Type Description queue_name text The name of the queue queue_length bigint Number of messages currently in the queue newest_msg_age_sec integer | null Age of the newest message in the queue, in seconds oldest_msg_age_sec integer | null Age of the oldest message in the queue, in seconds total_messages bigint Total number of messages that have passed through the queue over all time scrape_time timestamp with time zone The current timestamp queue_visible_length bigint Number of messages currently visible (vt &lt;= now) <p>Example:</p> <pre><code>select * from pgmq.metrics('my_queue');\n queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages |          scrape_time\n------------+--------------+--------------------+--------------------+----------------+-------------------------------\n my_queue   |           16 |               2445 |               2447 |             35 | 2023-10-28 20:23:08.406259-05\n</code></pre>"},{"location":"api/sql/functions/#metrics_all","title":"metrics_all","text":"<p>Get metrics for all existing queues.</p> <pre><code>pgmq.metrics_all()\nRETURNS SETOF pgmq.metrics_result\n</code></pre> <p>Returns:</p> Attribute Type Description queue_name text The name of the queue queue_length bigint Number of messages currently in the queue newest_msg_age_sec integer | null Age of the newest message in the queue, in seconds oldest_msg_age_sec integer | null Age of the oldest message in the queue, in seconds total_messages bigint Total number of messages that have passed through the queue over all time scrape_time timestamp with time zone The current timestamp queue_visible_length bigint Number of messages currently visible (vt &lt;= now) <pre><code>select * from pgmq.metrics_all();\n      queue_name      | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages |          scrape_time\n----------------------+--------------+--------------------+--------------------+----------------+-------------------------------\n my_queue             |           16 |               2563 |               2565 |             35 | 2023-10-28 20:25:07.016413-05\n my_partitioned_queue |            1 |                 11 |                 11 |              1 | 2023-10-28 20:25:07.016413-05\n my_unlogged          |            1 |                  3 |                  3 |              1 | 2023-10-28 20:25:07.016413-05\n</code></pre>"},{"location":"api/sql/functions/#enable_notify_insert","title":"enable_notify_insert","text":"<p>Enable PostgreSQL NOTIFY triggers for a queue with optional throttling. When enabled, a notification is sent on the channel <code>pgmq.&lt;queue_table&gt;.INSERT</code> every time a message is inserted (subject to throttling). This allows applications to use <code>LISTEN</code> to be notified immediately when new messages arrive, instead of polling.</p> <pre><code>pgmq.enable_notify_insert(queue_name text, throttle_interval_ms integer DEFAULT 250)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue throttle_interval_ms integer Minimum milliseconds between notifications. Set to 0 to disable throttling. Defaults to 250. <p>Notes:</p> <ul> <li> <p>The notification channel will be named <code>pgmq.q_&lt;queue_name&gt;.INSERT</code> where <code>q_&lt;queue_name&gt;</code> is the internal table name.</p> </li> <li> <p>Throttling behavior: Throttling prevents excessive notifications during high-volume inserts. When multiple messages are inserted rapidly, only one notification per throttle interval will be sent. This protects your system from notification overhead when message volume is high.</p> </li> <li> <p>When to use notifications: Notifications are most valuable for queues with sporadic or low-volume traffic. During high-volume periods, consumers can continuously poll and expect work to be present. However, when there are longer gaps between messages, notifications allow the consumer to wait idle and only poll when it receives a notification, significantly reducing unnecessary polling overhead. The throttling feature ensures that during burst traffic, you don't create excessive notifications while still maintaining the notification behavior during low-volume periods.</p> </li> </ul> <p>Examples:</p> <pre><code>-- Enable notifications with default 250ms throttling\nselect pgmq.enable_notify_insert('my_queue');\n enable_notify_insert\n----------------------\n\n-- Enable notifications with custom 500ms throttling\nselect pgmq.enable_notify_insert('my_queue', 500);\n enable_notify_insert\n----------------------\n\n-- Enable notifications with no throttling (0ms)\nselect pgmq.enable_notify_insert('my_queue', 0);\n enable_notify_insert\n----------------------\n\n-- In another session, listen for notifications:\n-- LISTEN \"pgmq.q_my_queue.INSERT\";\n</code></pre> <p>Changing throttling after enabling notifications:</p> <p>Use <code>update_notify_insert()</code> to modify the throttling interval for an existing queue:</p> <pre><code>-- Change throttling to 1000ms (1 second)\nSELECT pgmq.update_notify_insert('my_queue', 1000);\n\n-- Disable throttling (set to 0ms)\nSELECT pgmq.update_notify_insert('my_queue', 0);\n</code></pre> <p>See <code>update_notify_insert</code> for more details.</p>"},{"location":"api/sql/functions/#disable_notify_insert","title":"disable_notify_insert","text":"<p>Disable PostgreSQL NOTIFY triggers for a queue that were enabled with <code>enable_notify_insert()</code>.</p> <pre><code>pgmq.disable_notify_insert(queue_name text)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue <p>Example:</p> <pre><code>select pgmq.disable_notify_insert('my_queue');\n disable_notify_insert\n-----------------------\n</code></pre>"},{"location":"api/sql/functions/#update_notify_insert","title":"update_notify_insert","text":"<p>Update the throttle interval for a queue that has notifications enabled. This allows you to change the throttling rate without disabling and re-enabling notifications.</p> <pre><code>pgmq.update_notify_insert(queue_name text, throttle_interval_ms integer)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue throttle_interval_ms integer Minimum milliseconds between notifications (0 = no throttling) <p>Notes:</p> <ul> <li>The queue must have notifications enabled via <code>enable_notify_insert()</code> first</li> <li>Setting to 0 disables throttling (sends notification on every insert)</li> <li>Updating the throttle resets <code>last_notified_at</code> to ensure immediate notification on next insert</li> <li><code>throttle_interval_ms</code> must be non-negative</li> </ul> <p>Example:</p> <pre><code>-- Change throttling to 1 second\nselect pgmq.update_notify_insert('my_queue', 1000);\n update_notify_insert\n----------------------\n</code></pre>"},{"location":"api/sql/functions/#list_notify_insert_throttles","title":"list_notify_insert_throttles","text":"<p>Returns all notification throttle configurations for queues that have notifications enabled.</p> <pre><code>pgmq.list_notify_insert_throttles()\nRETURNS TABLE (\n    queue_name text,\n    throttle_interval_ms integer,\n    last_notified_at timestamp with time zone\n)\n</code></pre> <p>Returns:</p> Column Type Description queue_name text The name of the queue throttle_interval_ms integer Minimum milliseconds between notifications last_notified_at timestamp with time zone Timestamp of the last notification sent <p>Notes:</p> <ul> <li>Only returns queues that have notifications enabled</li> <li>Results are ordered by queue_name</li> <li>Empty result if no queues have notifications enabled</li> </ul> <p>Example:</p> <pre><code>select * from pgmq.list_notify_insert_throttles();\n   queue_name   | throttle_interval_ms |      last_notified_at\n----------------+----------------------+----------------------------\n my_queue       |                 1000 | 2024-01-15 10:30:45.123456\n another_queue  |                    0 | 1970-01-01 00:00:00.000000\n</code></pre>"},{"location":"api/sql/functions/#create_fifo_index","title":"create_fifo_index","text":"<p>Creates a GIN index on the headers column for a specific queue to improve FIFO read performance. This is recommended when using FIFO functionality frequently on a queue.</p> <pre><code>pgmq.create_fifo_index(queue_name text)\nRETURNS void\n</code></pre> <p>Parameters:</p> Parameter Type Description queue_name text The name of the queue <p>Example:</p> <pre><code>select pgmq.create_fifo_index('my_queue');\n create_fifo_index\n-------------------\n</code></pre>"},{"location":"api/sql/functions/#create_fifo_indexes_all","title":"create_fifo_indexes_all","text":"<p>Creates FIFO indexes on all existing queues. This is a convenience function to optimize all queues for FIFO operations.</p> <pre><code>pgmq.create_fifo_indexes_all()\nRETURNS void\n</code></pre> <p>Example:</p> <pre><code>select pgmq.create_fifo_indexes_all();\n create_fifo_indexes_all\n-------------------------\n</code></pre>"},{"location":"api/sql/types/","title":"Types","text":""},{"location":"api/sql/types/#message_record","title":"message_record","text":"<p>The complete representation of a message in a queue.</p> Attribute Name Type Description msg_id bigint Unique ID of the message read_ct integer Number of times the message has been read. Increments on read(). enqueued_at timestamp with time zone Timestamp when the message was inserted into the queue last_read_at timestamp with time zone Timestamp when the message was last read vt timestamp with time zone Timestamp when the message will become available for consumers to read message jsonb The message payload headers jsonb Optional message headers/metadata <p>Example:</p> <pre><code> msg_id | read_ct |          enqueued_at          |              vt              | message | headers \n--------+---------+-------------------------------+------------------------------+---------+---------\n      1 |       1 | 2026-01-23 19:59:43.333107-06 | 2026-01-23 20:00:13.60826-06 | {\"hello\": \"world\"}      | \n</code></pre>"},{"location":"api/sql/types/#queue_record","title":"queue_record","text":"<p>Represents metadata about a queue.</p> Attribute Name Type Description queue_name varchar Name of the queue is_partitioned boolean Whether the queue is partitioned is_unlogged boolean Whether the queue is unlogged (higher performance, less durability) created_at timestamp with time zone When the queue was created <p>Example:</p> <pre><code>      queue_name      |          created_at           | is_partitioned | is_unlogged\n----------------------+-------------------------------+----------------+-------------\n my_queue             | 2023-10-28 14:13:17.092576-05 | f              | f\n</code></pre>"},{"location":"api/sql/types/#metrics_result","title":"metrics_result","text":"<p>Contains metrics and statistics for a queue.</p> Attribute Name Type Description queue_name text Name of the queue queue_length bigint Total number of messages currently in the queue newest_msg_age_sec integer Age of the newest message in seconds (null if queue is empty) oldest_msg_age_sec integer Age of the oldest message in seconds (null if queue is empty) total_messages bigint Total number of messages that have ever been in the queue scrape_time timestamp with time zone Timestamp when metrics were collected queue_visible_length bigint Number of messages currently visible (vt &lt;= now) <p>Example:</p> <pre><code> queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages |          scrape_time          | queue_visible_length\n------------+--------------+--------------------+--------------------+----------------+-------------------------------+---------------------\n my_queue   |           16 |               2445 |               2447 |             35 | 2023-10-28 20:23:08.406259-05 |                  12\n</code></pre>"}]}