{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Postgres Message Queue (PGMQ) \u00b6 A lightweight message queue. Like AWS SQS and RSMQ but on Postgres. Documentation : https://pgmq.github.io/pgmq/ Source : https://github.com/pgmq/pgmq Features \u00b6 Lightweight - No background worker or external dependencies, just Postgres functions packaged in an extension Guaranteed \"exactly once\" delivery of messages to a consumer within a visibility timeout API parity with AWS SQS and RSMQ FIFO (First-In-First-Out) queues with message group keys for ordered processing Messages stay in the queue until explicitly removed Messages can be archived, instead of deleted, for long-term retention and replayability Supported on Postgres 14-18. Table of Contents \u00b6 Postgres Message Queue (PGMQ) Features Table of Contents Installation Updating Client Libraries SQL Examples Creating a queue Send two messages Read messages Pop a message Archive a message Delete a message Drop a queue Configuration Partitioned Queues Visibility Timeout (vt) Who uses pgmq? \u2728 Contributors Installation \u00b6 The fastest way to get started is by running the Docker image, where PGMQ comes pre-installed in Postgres. docker run -d --name pgmq-postgres -e POSTGRES_PASSWORD = postgres -p 5432 :5432 ghcr.io/pgmq/pg18-pgmq:v1.7.0 If you'd like to install PGMQ into an existing Postgres instance, refer to INSTALLATION.md . Updating \u00b6 To update PGMQ versions, follow the instructions in UPDATING.md . Client Libraries \u00b6 Rust Python (only for psycopg3) Community Dart Go Elixir Elixir + Broadway Java (JDBC) Java (Spring Boot) Kotlin JVM (JDBC) Kotlin Multiplatform (sqlx4k) Javascript (NodeJs) TypeScript (NodeJs + Midway.js ) TypeScript (Deno) .NET Python (with SQLAlchemy) REST-API (Bun + Elysia) Ruby TypeScript (NodeJs + Prisma) PHP (non blocking) Haskell SQL Examples \u00b6 # Connect to Postgres psql postgres://postgres:postgres@0.0.0.0:5432/postgres -- create the extension in the \"pgmq\" schema CREATE EXTENSION pgmq ; Creating a queue \u00b6 Every queue is its own table in the pgmq schema. The table name is the queue name prefixed with q_ . For example, pgmq.q_my_queue is the table for the queue my_queue . -- creates the queue SELECT pgmq . create ( 'my_queue' ); create ------------- (1 row) Send two messages \u00b6 -- messages are sent as JSON SELECT * from pgmq . send ( queue_name => 'my_queue' , msg => '{\"foo\": \"bar1\"}' ); The message id is returned from the send function. send ----------- 1 (1 row) -- Optionally provide a delay -- this message will be on the queue but unable to be consumed for 5 seconds SELECT * from pgmq . send ( queue_name => 'my_queue' , msg => '{\"foo\": \"bar2\"}' , delay => 5 ); send ----------- 2 (1 row) Read messages \u00b6 Read 2 message from the queue. Make them invisible for 30 seconds. If the messages are not deleted or archived within 30 seconds, they will become visible again and can be read by another consumer. SELECT * FROM pgmq . read ( queue_name => 'my_queue' , vt => 30 , qty => 2 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+------------------+--------- 1 | 1 | 2023-08-16 08:37:54.567283-05 | 2023-08-16 08:38:29.989841-05 | {\"foo\": \"bar1\"} | 2 | 1 | 2023-08-16 08:37:54.572933-05 | 2023-08-16 08:38:29.989841-05 | {\"foo\": \"bar2\"} | If the queue is empty, or if all messages are currently invisible, no rows will be returned. SELECT * FROM pgmq . read ( queue_name => 'my_queue' , vt => 30 , qty => 1 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------+----+---------+--------- Pop a message \u00b6 -- Read a message and immediately delete it from the queue. Returns an empty record if the queue is empty or all messages are invisible. SELECT * FROM pgmq . pop ( 'my_queue' ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+------------------+--------- 1 | 1 | 2023-08-16 08:37:54.567283-05 | 2023-08-16 08:38:29.989841-05 | {\"foo\": \"bar1\"} | Archive a message \u00b6 Archiving a message removes it from the queue and inserts it to the archive table. -- Archive message with msg_id=2. SELECT pgmq . archive ( queue_name => 'my_queue' , msg_id => 2 ); archive -------------- t (1 row) Or archive several messages in one operation using msg_ids (plural) parameter: First, send a batch of messages SELECT pgmq . send_batch ( queue_name => 'my_queue' , msgs => ARRAY [ '{\"foo\": \"bar3\"}' , '{\"foo\": \"bar4\"}' , '{\"foo\": \"bar5\"}' ]:: jsonb [] ); send_batch ------------ 3 4 5 (3 rows) Then archive them by using the msg_ids (plural) parameter. SELECT pgmq . archive ( queue_name => 'my_queue' , msg_ids => ARRAY [ 3 , 4 , 5 ] ); archive --------- 3 4 5 (3 rows) Archive tables can be inspected directly with SQL. Archive tables have the prefix a_ in the pgmq schema. SELECT * FROM pgmq . a_my_queue ; msg_id | read_ct | enqueued_at | archived_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-------------------------------+------------------+--------- 2 | 0 | 2024-08-06 16:03:41.531556+00 | 2024-08-06 16:03:52.811063+00 | 2024-08-06 16:03:46.532246+00 | {\"foo\": \"bar2\"} | 3 | 0 | 2024-08-06 16:03:58.586444+00 | 2024-08-06 16:04:02.85799+00 | 2024-08-06 16:03:58.587272+00 | {\"foo\": \"bar3\"} | 4 | 0 | 2024-08-06 16:03:58.586444+00 | 2024-08-06 16:04:02.85799+00 | 2024-08-06 16:03:58.587508+00 | {\"foo\": \"bar4\"} | 5 | 0 | 2024-08-06 16:03:58.586444+00 | 2024-08-06 16:04:02.85799+00 | 2024-08-06 16:03:58.587543+00 | {\"foo\": \"bar5\"} | Delete a message \u00b6 Send another message, so that we can delete it. SELECT pgmq . send ( 'my_queue' , '{\"foo\": \"bar6\"}' ); send ----------- 6 (1 row) Delete the message with id 6 from the queue named my_queue . SELECT pgmq . delete ( 'my_queue' , 6 ); delete ------------- t (1 row) Drop a queue \u00b6 Delete the queue my_queue . SELECT pgmq . drop_queue ( 'my_queue' ); drop_queue ----------------- t (1 row) Configuration \u00b6 Partitioned Queues \u00b6 You will need to install pg_partman if you want to use pgmq partitioned queues. pgmq queue tables can be created as a partitioned table by using pgmq.create_partitioned() . pg_partman handles all maintenance of queue tables. This includes creating new partitions and dropping old partitions. Partitions behavior is configured at the time queues are created, via pgmq.create_partitioned() . This function has three parameters: queue_name: text : The name of the queue. Queues are Postgres tables prepended with q_ . For example, q_my_queue . The archive is instead prefixed by a_ , for example a_my_queue . partition_interval: text - The interval at which partitions are created. This can be either any valid Postgres Duration supported by pg_partman, or an integer value. When it is a duration, queues are partitioned by the time at which messages are sent to the table ( enqueued_at ). A value of 'daily' would create a new partition each day. When it is an integer value, queues are partitioned by the msg_id . A value of '100' will create a new partition every 100 messages. The value must agree with retention_interval (time based or numeric). The default value is '10000' . For archive table, when interval is an integer value, then it will be partitioned by msg_id . In case of duration it will be partitioned on archived_at unlike queue table. retention_interval: text - The interval for retaining partitions. This can be either any valid Postgres Duration supported by pg_partman, or an integer value. When it is a duration, partitions containing data greater than the duration will be dropped. When it is an integer value, any messages that have a msg_id less than max(msg_id) - retention_interval will be dropped. For example, if the max msg_id is 100 and the retention_interval is 60, any partitions with msg_id values less than 40 will be dropped. The value must agree with partition_interval (time based or numeric). The default is '100000' . Note: retention_interval does not apply to messages that have been deleted via pgmq.delete() or archived with pgmq.archive() . pgmq.delete() removes messages forever and pgmq.archive() moves messages to the corresponding archive table forever (for example, a_my_queue ). In order for automatic partition maintenance to take place, several settings must be added to the postgresql.conf file, which is typically located in the postgres DATADIR . pg_partman_bgw.interval in postgresql.conf . Below are the default configuration values set in pgmq docker images. Add the following to postgresql.conf . Note, changing shared_preload_libraries requires a restart of Postgres. pg_partman_bgw.interval sets the interval at which pg_partman conducts maintenance. This creates new partitions and dropping of partitions falling out of the retention_interval . By default, pg_partman will keep 4 partitions \"ahead\" of the currently active partition. shared_preload_libraries = 'pg_partman_bgw' # requires restart of Postgres pg_partman_bgw.interval = 60 pg_partman_bgw.role = 'postgres' pg_partman_bgw.dbname = 'postgres' Visibility Timeout (vt) \u00b6 pgmq guarantees exactly once delivery of a message within a visibility timeout. The visibility timeout is the amount of time a message is invisible to other consumers after it has been read by a consumer. If the message is NOT deleted or archived within the visibility timeout, it will become visible again and can be read by another consumer. The visibility timeout is set when a message is read from the queue, via pgmq.read() . It is recommended to set a vt value that is greater than the expected time it takes to process a message. After the application successfully processes the message, it should call pgmq.delete() to completely remove the message from the queue or pgmq.archive() to move it to the archive table for the queue. Who uses pgmq? \u00b6 As the pgmq community grows, we'd love to see who is using it. Please send a PR with your company name and @githubhandle. Currently, officially using pgmq: Tembo [ @Tembo-io ] Supabase [ @Supabase ] Sprinters [ @sprinters-sh ] pgflow [ @pgflow-dev/pgflow ] \u2728 Contributors \u00b6 Thanks goes to these incredible people:","title":"PGMQ"},{"location":"#postgres-message-queue-pgmq","text":"A lightweight message queue. Like AWS SQS and RSMQ but on Postgres. Documentation : https://pgmq.github.io/pgmq/ Source : https://github.com/pgmq/pgmq","title":"Postgres Message Queue (PGMQ)"},{"location":"#features","text":"Lightweight - No background worker or external dependencies, just Postgres functions packaged in an extension Guaranteed \"exactly once\" delivery of messages to a consumer within a visibility timeout API parity with AWS SQS and RSMQ FIFO (First-In-First-Out) queues with message group keys for ordered processing Messages stay in the queue until explicitly removed Messages can be archived, instead of deleted, for long-term retention and replayability Supported on Postgres 14-18.","title":"Features"},{"location":"#table-of-contents","text":"Postgres Message Queue (PGMQ) Features Table of Contents Installation Updating Client Libraries SQL Examples Creating a queue Send two messages Read messages Pop a message Archive a message Delete a message Drop a queue Configuration Partitioned Queues Visibility Timeout (vt) Who uses pgmq? \u2728 Contributors","title":"Table of Contents"},{"location":"#installation","text":"The fastest way to get started is by running the Docker image, where PGMQ comes pre-installed in Postgres. docker run -d --name pgmq-postgres -e POSTGRES_PASSWORD = postgres -p 5432 :5432 ghcr.io/pgmq/pg18-pgmq:v1.7.0 If you'd like to install PGMQ into an existing Postgres instance, refer to INSTALLATION.md .","title":"Installation"},{"location":"#updating","text":"To update PGMQ versions, follow the instructions in UPDATING.md .","title":"Updating"},{"location":"#client-libraries","text":"Rust Python (only for psycopg3) Community Dart Go Elixir Elixir + Broadway Java (JDBC) Java (Spring Boot) Kotlin JVM (JDBC) Kotlin Multiplatform (sqlx4k) Javascript (NodeJs) TypeScript (NodeJs + Midway.js ) TypeScript (Deno) .NET Python (with SQLAlchemy) REST-API (Bun + Elysia) Ruby TypeScript (NodeJs + Prisma) PHP (non blocking) Haskell","title":"Client Libraries"},{"location":"#sql-examples","text":"# Connect to Postgres psql postgres://postgres:postgres@0.0.0.0:5432/postgres -- create the extension in the \"pgmq\" schema CREATE EXTENSION pgmq ;","title":"SQL Examples"},{"location":"#creating-a-queue","text":"Every queue is its own table in the pgmq schema. The table name is the queue name prefixed with q_ . For example, pgmq.q_my_queue is the table for the queue my_queue . -- creates the queue SELECT pgmq . create ( 'my_queue' ); create ------------- (1 row)","title":"Creating a queue"},{"location":"#send-two-messages","text":"-- messages are sent as JSON SELECT * from pgmq . send ( queue_name => 'my_queue' , msg => '{\"foo\": \"bar1\"}' ); The message id is returned from the send function. send ----------- 1 (1 row) -- Optionally provide a delay -- this message will be on the queue but unable to be consumed for 5 seconds SELECT * from pgmq . send ( queue_name => 'my_queue' , msg => '{\"foo\": \"bar2\"}' , delay => 5 ); send ----------- 2 (1 row)","title":"Send two messages"},{"location":"#read-messages","text":"Read 2 message from the queue. Make them invisible for 30 seconds. If the messages are not deleted or archived within 30 seconds, they will become visible again and can be read by another consumer. SELECT * FROM pgmq . read ( queue_name => 'my_queue' , vt => 30 , qty => 2 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+------------------+--------- 1 | 1 | 2023-08-16 08:37:54.567283-05 | 2023-08-16 08:38:29.989841-05 | {\"foo\": \"bar1\"} | 2 | 1 | 2023-08-16 08:37:54.572933-05 | 2023-08-16 08:38:29.989841-05 | {\"foo\": \"bar2\"} | If the queue is empty, or if all messages are currently invisible, no rows will be returned. SELECT * FROM pgmq . read ( queue_name => 'my_queue' , vt => 30 , qty => 1 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------+----+---------+---------","title":"Read messages"},{"location":"#pop-a-message","text":"-- Read a message and immediately delete it from the queue. Returns an empty record if the queue is empty or all messages are invisible. SELECT * FROM pgmq . pop ( 'my_queue' ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+------------------+--------- 1 | 1 | 2023-08-16 08:37:54.567283-05 | 2023-08-16 08:38:29.989841-05 | {\"foo\": \"bar1\"} |","title":"Pop a message"},{"location":"#archive-a-message","text":"Archiving a message removes it from the queue and inserts it to the archive table. -- Archive message with msg_id=2. SELECT pgmq . archive ( queue_name => 'my_queue' , msg_id => 2 ); archive -------------- t (1 row) Or archive several messages in one operation using msg_ids (plural) parameter: First, send a batch of messages SELECT pgmq . send_batch ( queue_name => 'my_queue' , msgs => ARRAY [ '{\"foo\": \"bar3\"}' , '{\"foo\": \"bar4\"}' , '{\"foo\": \"bar5\"}' ]:: jsonb [] ); send_batch ------------ 3 4 5 (3 rows) Then archive them by using the msg_ids (plural) parameter. SELECT pgmq . archive ( queue_name => 'my_queue' , msg_ids => ARRAY [ 3 , 4 , 5 ] ); archive --------- 3 4 5 (3 rows) Archive tables can be inspected directly with SQL. Archive tables have the prefix a_ in the pgmq schema. SELECT * FROM pgmq . a_my_queue ; msg_id | read_ct | enqueued_at | archived_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-------------------------------+------------------+--------- 2 | 0 | 2024-08-06 16:03:41.531556+00 | 2024-08-06 16:03:52.811063+00 | 2024-08-06 16:03:46.532246+00 | {\"foo\": \"bar2\"} | 3 | 0 | 2024-08-06 16:03:58.586444+00 | 2024-08-06 16:04:02.85799+00 | 2024-08-06 16:03:58.587272+00 | {\"foo\": \"bar3\"} | 4 | 0 | 2024-08-06 16:03:58.586444+00 | 2024-08-06 16:04:02.85799+00 | 2024-08-06 16:03:58.587508+00 | {\"foo\": \"bar4\"} | 5 | 0 | 2024-08-06 16:03:58.586444+00 | 2024-08-06 16:04:02.85799+00 | 2024-08-06 16:03:58.587543+00 | {\"foo\": \"bar5\"} |","title":"Archive a message"},{"location":"#delete-a-message","text":"Send another message, so that we can delete it. SELECT pgmq . send ( 'my_queue' , '{\"foo\": \"bar6\"}' ); send ----------- 6 (1 row) Delete the message with id 6 from the queue named my_queue . SELECT pgmq . delete ( 'my_queue' , 6 ); delete ------------- t (1 row)","title":"Delete a message"},{"location":"#drop-a-queue","text":"Delete the queue my_queue . SELECT pgmq . drop_queue ( 'my_queue' ); drop_queue ----------------- t (1 row)","title":"Drop a queue"},{"location":"#configuration","text":"","title":"Configuration"},{"location":"#partitioned-queues","text":"You will need to install pg_partman if you want to use pgmq partitioned queues. pgmq queue tables can be created as a partitioned table by using pgmq.create_partitioned() . pg_partman handles all maintenance of queue tables. This includes creating new partitions and dropping old partitions. Partitions behavior is configured at the time queues are created, via pgmq.create_partitioned() . This function has three parameters: queue_name: text : The name of the queue. Queues are Postgres tables prepended with q_ . For example, q_my_queue . The archive is instead prefixed by a_ , for example a_my_queue . partition_interval: text - The interval at which partitions are created. This can be either any valid Postgres Duration supported by pg_partman, or an integer value. When it is a duration, queues are partitioned by the time at which messages are sent to the table ( enqueued_at ). A value of 'daily' would create a new partition each day. When it is an integer value, queues are partitioned by the msg_id . A value of '100' will create a new partition every 100 messages. The value must agree with retention_interval (time based or numeric). The default value is '10000' . For archive table, when interval is an integer value, then it will be partitioned by msg_id . In case of duration it will be partitioned on archived_at unlike queue table. retention_interval: text - The interval for retaining partitions. This can be either any valid Postgres Duration supported by pg_partman, or an integer value. When it is a duration, partitions containing data greater than the duration will be dropped. When it is an integer value, any messages that have a msg_id less than max(msg_id) - retention_interval will be dropped. For example, if the max msg_id is 100 and the retention_interval is 60, any partitions with msg_id values less than 40 will be dropped. The value must agree with partition_interval (time based or numeric). The default is '100000' . Note: retention_interval does not apply to messages that have been deleted via pgmq.delete() or archived with pgmq.archive() . pgmq.delete() removes messages forever and pgmq.archive() moves messages to the corresponding archive table forever (for example, a_my_queue ). In order for automatic partition maintenance to take place, several settings must be added to the postgresql.conf file, which is typically located in the postgres DATADIR . pg_partman_bgw.interval in postgresql.conf . Below are the default configuration values set in pgmq docker images. Add the following to postgresql.conf . Note, changing shared_preload_libraries requires a restart of Postgres. pg_partman_bgw.interval sets the interval at which pg_partman conducts maintenance. This creates new partitions and dropping of partitions falling out of the retention_interval . By default, pg_partman will keep 4 partitions \"ahead\" of the currently active partition. shared_preload_libraries = 'pg_partman_bgw' # requires restart of Postgres pg_partman_bgw.interval = 60 pg_partman_bgw.role = 'postgres' pg_partman_bgw.dbname = 'postgres'","title":"Partitioned Queues"},{"location":"#visibility-timeout-vt","text":"pgmq guarantees exactly once delivery of a message within a visibility timeout. The visibility timeout is the amount of time a message is invisible to other consumers after it has been read by a consumer. If the message is NOT deleted or archived within the visibility timeout, it will become visible again and can be read by another consumer. The visibility timeout is set when a message is read from the queue, via pgmq.read() . It is recommended to set a vt value that is greater than the expected time it takes to process a message. After the application successfully processes the message, it should call pgmq.delete() to completely remove the message from the queue or pgmq.archive() to move it to the archive table for the queue.","title":"Visibility Timeout (vt)"},{"location":"#who-uses-pgmq","text":"As the pgmq community grows, we'd love to see who is using it. Please send a PR with your company name and @githubhandle. Currently, officially using pgmq: Tembo [ @Tembo-io ] Supabase [ @Supabase ] Sprinters [ @sprinters-sh ] pgflow [ @pgflow-dev/pgflow ]","title":"Who uses pgmq?"},{"location":"#contributors","text":"Thanks goes to these incredible people:","title":"\u2728 Contributors"},{"location":"fifo-queues/","text":"FIFO Queues \u00b6 PGMQ supports FIFO (First-In-First-Out) queues with message group keys, similar to AWS SQS FIFO queues. This feature allows you to ensure strict ordering of messages within logical groups while still allowing parallel processing across different groups. Overview \u00b6 FIFO queues in PGMQ work by using message headers to specify group identifiers. Messages with the same group ID are processed in strict order, while messages from different groups can be processed in parallel. Key Features \u00b6 Strict ordering within groups : Messages with the same FIFO group ID are processed in the exact order they were sent Parallel processing across groups : Different FIFO groups can be processed simultaneously Backward compatibility : Existing queues work unchanged; FIFO is opt-in via headers Visibility timeout support : FIFO respects visibility timeouts to prevent duplicate processing Performance optimized : Uses efficient indexing for FIFO group lookups How It Works \u00b6 Message Group IDs \u00b6 FIFO ordering is controlled by the x-pgmq-group header value: -- Send messages to the same FIFO group SELECT pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user123\"}' ); SELECT pgmq . send ( 'my_queue' , '{\"order\": 2}' , '{\"x-pgmq-group\": \"user123\"}' ); -- Send message to different FIFO group SELECT pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user456\"}' ); Reading FIFO Messages \u00b6 PGMQ provides two FIFO reading strategies. Choose the one that best fits your workload: pgmq.read_grouped_rr(...) (Round-Robin, layered interleaving): Fairly interleaves messages across groups. Great for multi-tenant and user-centric workloads. pgmq.read_grouped(...) (SQS-style throughput): Fills batches from the oldest eligible group first, returning multiple messages from the same group for throughput. -- Fair distribution across groups (round-robin, layered) SELECT * FROM pgmq . read_grouped_rr ( 'my_queue' , 30 , 5 ); -- Throughput-optimized, SQS-style batch filling SELECT * FROM pgmq . read_grouped ( 'my_queue' , 30 , 5 ); Round-robin (RR) will: - Interleave across groups in layers, preserving order within each group - Return up to the requested quantity across groups - Prevent starvation of smaller/less-active groups SQS-style will: - Fill the batch from the earliest eligible group first - Return multiple messages from the same group when available - Move to other groups only if needed to fill the batch Default Group Behavior \u00b6 Messages without the x-pgmq-group header are treated as belonging to a single default group: -- These messages will be processed in FIFO order relative to each other SELECT pgmq . send ( 'my_queue' , '{\"message\": \"first\"}' ); SELECT pgmq . send ( 'my_queue' , '{\"message\": \"second\"}' ); API Reference \u00b6 Reading Functions \u00b6 pgmq.read_grouped_rr(queue_name, vt, qty) \u00b6 Read messages while respecting FIFO ordering within groups. Parameters: - queue_name (text): Name of the queue - vt (integer): Visibility timeout in seconds - qty (integer): Maximum number of messages to read pgmq.read_grouped_rr_with_poll(queue_name, vt, qty, max_poll_seconds, poll_interval_ms) \u00b6 Same as read_grouped_rr() but with polling support for real-time processing. pgmq.read_grouped(queue_name, vt, qty) \u00b6 Read messages with AWS SQS FIFO-style batch retrieval behavior. Unlike read_grouped_rr() which interleaves fairly across groups, this function attempts to return as many messages as possible from the same message group to maximize throughput for related messages. Behavior: - Prioritizes filling the batch from the earliest message group first - Returns multiple messages from the same group when available - Only moves to other groups if the batch cannot be filled from the first group - Maintains strict FIFO ordering within each group pgmq.read_grouped_with_poll(queue_name, vt, qty, max_poll_seconds, poll_interval_ms) \u00b6 Same as read_grouped() but with polling support for real-time processing. Utility Functions \u00b6 pgmq.create_fifo_index(queue_name) \u00b6 Creates a GIN index on the headers column to improve FIFO read performance. Recommended when using FIFO functionality frequently. pgmq.create_fifo_indexes_all() \u00b6 Creates FIFO indexes on all existing queues. Usage Patterns \u00b6 1. User-Specific Processing \u00b6 Ensure messages for each user are processed in order: -- User 1 messages SELECT pgmq . send ( 'user_events' , '{\"action\": \"login\"}' , '{\"x-pgmq-group\": \"user_123\"}' ); SELECT pgmq . send ( 'user_events' , '{\"action\": \"purchase\"}' , '{\"x-pgmq-group\": \"user_123\"}' ); -- User 2 messages (can be processed in parallel) SELECT pgmq . send ( 'user_events' , '{\"action\": \"login\"}' , '{\"x-pgmq-group\": \"user_456\"}' ); 2. Order Processing \u00b6 Maintain order integrity for financial transactions: -- Order lifecycle events SELECT pgmq . send ( 'orders' , '{\"order_id\": \"ord_1\", \"action\": \"create\"}' , '{\"x-pgmq-group\": \"ord_1\"}' ); SELECT pgmq . send ( 'orders' , '{\"order_id\": \"ord_1\", \"action\": \"payment\"}' , '{\"x-pgmq-group\": \"ord_1\"}' ); SELECT pgmq . send ( 'orders' , '{\"order_id\": \"ord_1\", \"action\": \"fulfill\"}' , '{\"x-pgmq-group\": \"ord_1\"}' ); 3. Document Processing \u00b6 Process document versions in sequence: -- Document updates SELECT pgmq . send ( 'docs' , '{\"doc_id\": \"doc_1\", \"version\": 1}' , '{\"x-pgmq-group\": \"doc_1\"}' ); SELECT pgmq . send ( 'docs' , '{\"doc_id\": \"doc_1\", \"version\": 2}' , '{\"x-pgmq-group\": \"doc_1\"}' ); Performance Considerations \u00b6 Indexing \u00b6 Create FIFO indexes for better performance: -- For a specific queue SELECT pgmq . create_fifo_index ( 'my_queue' ); -- For all queues SELECT pgmq . create_fifo_indexes_all (); Group Distribution \u00b6 Good : Many small groups with few messages each Avoid : Few large groups with many messages (reduces parallelism) Message Processing \u00b6 Process and delete/archive messages promptly to avoid blocking subsequent messages Use appropriate visibility timeouts to handle processing failures Monitor queue metrics to identify bottlenecks Error Handling \u00b6 Visibility Timeout Expiry \u00b6 If message processing fails, the visibility timeout will expire and the message becomes available again: -- Message fails processing, timeout expires -- Next read_grouped() call will return the same message for retry Manual Retry \u00b6 Force a message to be immediately available: -- Set visibility timeout to 0 for immediate retry SELECT pgmq . set_vt ( 'my_queue' , 123 , 0 ); Dead Letter Handling \u00b6 Archive messages that fail repeatedly: -- After max retries, archive the problematic message SELECT pgmq . archive ( 'my_queue' , 123 ); Migration from Regular Queues \u00b6 FIFO functionality is backward compatible: Existing code continues to work : pgmq.read() functions unchanged Gradual adoption : Start using pgmq.read_grouped_rr() or pgmq.read_grouped() for new consumers Mixed usage : Some consumers can use FIFO, others regular reads Performance : Add FIFO indexes when ready to optimize FIFO Reading Strategies \u00b6 PGMQ provides two different FIFO reading strategies to suit different use cases: Fair Distribution ( pgmq.read_grouped_rr() ) \u00b6 Interleaves messages across FIFO groups in layers: -- With groups A (5 messages), B (3 messages), C (2 messages) SELECT * FROM pgmq . read_grouped_rr ( 'queue' , 30 , 10 ); -- Returns (layered interleaving): A1, B1, C1, A2, B2, C2, A3, B3, A4, ... Best for: - Ensuring fair processing across all groups - Preventing starvation of groups with fewer messages - Load balancing across different workflows Throughput Optimization ( pgmq.read_grouped() ) \u00b6 Attempts to fill the batch from the earliest group first: -- With groups A (5 messages), B (3 messages), C (2 messages) SELECT * FROM pgmq . read_grouped ( 'queue' , 30 , 10 ); -- Returns: 10 messages (5 from A + 3 from B + 2 from C) SELECT * FROM pgmq . read_grouped ( 'queue' , 30 , 3 ); -- Returns: 3 messages (all from group A) Best for: - Maximizing throughput for related messages - Processing workflows where batching related messages is beneficial - Mimicking AWS SQS FIFO behavior exactly Choosing the Right Strategy \u00b6 Scenario Recommended Function Reason Multi-tenant processing read_grouped_rr() Ensures fair resource allocation Order processing pipeline read_grouped() Related orders processed together User activity streams read_grouped_rr() Prevents one active user from blocking others Document workflows read_grouped() Process all versions of a document together Financial transactions read_grouped() Batch related transactions for efficiency Comparison with AWS SQS FIFO \u00b6 Feature PGMQ FIFO (RR) PGMQ read_grouped AWS SQS FIFO Group-based ordering \u2705 \u2705 \u2705 Parallel group processing \u2705 \u2705 \u2705 Batch retrieval strategy Fair (layered interleaving) Throughput-optimized Throughput-optimized Message deduplication \u274c \u274c \u2705 Throughput limits No limits No limits 300 TPS per group Exactly-once delivery \u274c \u274c \u2705 Cost Free Free Pay per request Best Practices \u00b6 Choose appropriate group keys : Balance between ordering requirements and parallelism Create FIFO indexes : Improve performance for frequently used queues Monitor group distribution : Ensure even distribution across groups Handle failures gracefully : Implement retry logic and dead letter handling Test thoroughly : Verify ordering behavior under load Use meaningful group IDs : Make debugging and monitoring easier Examples \u00b6 See examples/fifo_example.sql for comprehensive usage examples.","title":"FIFO Queues"},{"location":"fifo-queues/#fifo-queues","text":"PGMQ supports FIFO (First-In-First-Out) queues with message group keys, similar to AWS SQS FIFO queues. This feature allows you to ensure strict ordering of messages within logical groups while still allowing parallel processing across different groups.","title":"FIFO Queues"},{"location":"fifo-queues/#overview","text":"FIFO queues in PGMQ work by using message headers to specify group identifiers. Messages with the same group ID are processed in strict order, while messages from different groups can be processed in parallel.","title":"Overview"},{"location":"fifo-queues/#key-features","text":"Strict ordering within groups : Messages with the same FIFO group ID are processed in the exact order they were sent Parallel processing across groups : Different FIFO groups can be processed simultaneously Backward compatibility : Existing queues work unchanged; FIFO is opt-in via headers Visibility timeout support : FIFO respects visibility timeouts to prevent duplicate processing Performance optimized : Uses efficient indexing for FIFO group lookups","title":"Key Features"},{"location":"fifo-queues/#how-it-works","text":"","title":"How It Works"},{"location":"fifo-queues/#message-group-ids","text":"FIFO ordering is controlled by the x-pgmq-group header value: -- Send messages to the same FIFO group SELECT pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user123\"}' ); SELECT pgmq . send ( 'my_queue' , '{\"order\": 2}' , '{\"x-pgmq-group\": \"user123\"}' ); -- Send message to different FIFO group SELECT pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user456\"}' );","title":"Message Group IDs"},{"location":"fifo-queues/#reading-fifo-messages","text":"PGMQ provides two FIFO reading strategies. Choose the one that best fits your workload: pgmq.read_grouped_rr(...) (Round-Robin, layered interleaving): Fairly interleaves messages across groups. Great for multi-tenant and user-centric workloads. pgmq.read_grouped(...) (SQS-style throughput): Fills batches from the oldest eligible group first, returning multiple messages from the same group for throughput. -- Fair distribution across groups (round-robin, layered) SELECT * FROM pgmq . read_grouped_rr ( 'my_queue' , 30 , 5 ); -- Throughput-optimized, SQS-style batch filling SELECT * FROM pgmq . read_grouped ( 'my_queue' , 30 , 5 ); Round-robin (RR) will: - Interleave across groups in layers, preserving order within each group - Return up to the requested quantity across groups - Prevent starvation of smaller/less-active groups SQS-style will: - Fill the batch from the earliest eligible group first - Return multiple messages from the same group when available - Move to other groups only if needed to fill the batch","title":"Reading FIFO Messages"},{"location":"fifo-queues/#default-group-behavior","text":"Messages without the x-pgmq-group header are treated as belonging to a single default group: -- These messages will be processed in FIFO order relative to each other SELECT pgmq . send ( 'my_queue' , '{\"message\": \"first\"}' ); SELECT pgmq . send ( 'my_queue' , '{\"message\": \"second\"}' );","title":"Default Group Behavior"},{"location":"fifo-queues/#api-reference","text":"","title":"API Reference"},{"location":"fifo-queues/#reading-functions","text":"","title":"Reading Functions"},{"location":"fifo-queues/#pgmqread_grouped_rrqueue_name-vt-qty","text":"Read messages while respecting FIFO ordering within groups. Parameters: - queue_name (text): Name of the queue - vt (integer): Visibility timeout in seconds - qty (integer): Maximum number of messages to read","title":"pgmq.read_grouped_rr(queue_name, vt, qty)"},{"location":"fifo-queues/#pgmqread_grouped_rr_with_pollqueue_name-vt-qty-max_poll_seconds-poll_interval_ms","text":"Same as read_grouped_rr() but with polling support for real-time processing.","title":"pgmq.read_grouped_rr_with_poll(queue_name, vt, qty, max_poll_seconds, poll_interval_ms)"},{"location":"fifo-queues/#pgmqread_groupedqueue_name-vt-qty","text":"Read messages with AWS SQS FIFO-style batch retrieval behavior. Unlike read_grouped_rr() which interleaves fairly across groups, this function attempts to return as many messages as possible from the same message group to maximize throughput for related messages. Behavior: - Prioritizes filling the batch from the earliest message group first - Returns multiple messages from the same group when available - Only moves to other groups if the batch cannot be filled from the first group - Maintains strict FIFO ordering within each group","title":"pgmq.read_grouped(queue_name, vt, qty)"},{"location":"fifo-queues/#pgmqread_grouped_with_pollqueue_name-vt-qty-max_poll_seconds-poll_interval_ms","text":"Same as read_grouped() but with polling support for real-time processing.","title":"pgmq.read_grouped_with_poll(queue_name, vt, qty, max_poll_seconds, poll_interval_ms)"},{"location":"fifo-queues/#utility-functions","text":"","title":"Utility Functions"},{"location":"fifo-queues/#pgmqcreate_fifo_indexqueue_name","text":"Creates a GIN index on the headers column to improve FIFO read performance. Recommended when using FIFO functionality frequently.","title":"pgmq.create_fifo_index(queue_name)"},{"location":"fifo-queues/#pgmqcreate_fifo_indexes_all","text":"Creates FIFO indexes on all existing queues.","title":"pgmq.create_fifo_indexes_all()"},{"location":"fifo-queues/#usage-patterns","text":"","title":"Usage Patterns"},{"location":"fifo-queues/#1-user-specific-processing","text":"Ensure messages for each user are processed in order: -- User 1 messages SELECT pgmq . send ( 'user_events' , '{\"action\": \"login\"}' , '{\"x-pgmq-group\": \"user_123\"}' ); SELECT pgmq . send ( 'user_events' , '{\"action\": \"purchase\"}' , '{\"x-pgmq-group\": \"user_123\"}' ); -- User 2 messages (can be processed in parallel) SELECT pgmq . send ( 'user_events' , '{\"action\": \"login\"}' , '{\"x-pgmq-group\": \"user_456\"}' );","title":"1. User-Specific Processing"},{"location":"fifo-queues/#2-order-processing","text":"Maintain order integrity for financial transactions: -- Order lifecycle events SELECT pgmq . send ( 'orders' , '{\"order_id\": \"ord_1\", \"action\": \"create\"}' , '{\"x-pgmq-group\": \"ord_1\"}' ); SELECT pgmq . send ( 'orders' , '{\"order_id\": \"ord_1\", \"action\": \"payment\"}' , '{\"x-pgmq-group\": \"ord_1\"}' ); SELECT pgmq . send ( 'orders' , '{\"order_id\": \"ord_1\", \"action\": \"fulfill\"}' , '{\"x-pgmq-group\": \"ord_1\"}' );","title":"2. Order Processing"},{"location":"fifo-queues/#3-document-processing","text":"Process document versions in sequence: -- Document updates SELECT pgmq . send ( 'docs' , '{\"doc_id\": \"doc_1\", \"version\": 1}' , '{\"x-pgmq-group\": \"doc_1\"}' ); SELECT pgmq . send ( 'docs' , '{\"doc_id\": \"doc_1\", \"version\": 2}' , '{\"x-pgmq-group\": \"doc_1\"}' );","title":"3. Document Processing"},{"location":"fifo-queues/#performance-considerations","text":"","title":"Performance Considerations"},{"location":"fifo-queues/#indexing","text":"Create FIFO indexes for better performance: -- For a specific queue SELECT pgmq . create_fifo_index ( 'my_queue' ); -- For all queues SELECT pgmq . create_fifo_indexes_all ();","title":"Indexing"},{"location":"fifo-queues/#group-distribution","text":"Good : Many small groups with few messages each Avoid : Few large groups with many messages (reduces parallelism)","title":"Group Distribution"},{"location":"fifo-queues/#message-processing","text":"Process and delete/archive messages promptly to avoid blocking subsequent messages Use appropriate visibility timeouts to handle processing failures Monitor queue metrics to identify bottlenecks","title":"Message Processing"},{"location":"fifo-queues/#error-handling","text":"","title":"Error Handling"},{"location":"fifo-queues/#visibility-timeout-expiry","text":"If message processing fails, the visibility timeout will expire and the message becomes available again: -- Message fails processing, timeout expires -- Next read_grouped() call will return the same message for retry","title":"Visibility Timeout Expiry"},{"location":"fifo-queues/#manual-retry","text":"Force a message to be immediately available: -- Set visibility timeout to 0 for immediate retry SELECT pgmq . set_vt ( 'my_queue' , 123 , 0 );","title":"Manual Retry"},{"location":"fifo-queues/#dead-letter-handling","text":"Archive messages that fail repeatedly: -- After max retries, archive the problematic message SELECT pgmq . archive ( 'my_queue' , 123 );","title":"Dead Letter Handling"},{"location":"fifo-queues/#migration-from-regular-queues","text":"FIFO functionality is backward compatible: Existing code continues to work : pgmq.read() functions unchanged Gradual adoption : Start using pgmq.read_grouped_rr() or pgmq.read_grouped() for new consumers Mixed usage : Some consumers can use FIFO, others regular reads Performance : Add FIFO indexes when ready to optimize","title":"Migration from Regular Queues"},{"location":"fifo-queues/#fifo-reading-strategies","text":"PGMQ provides two different FIFO reading strategies to suit different use cases:","title":"FIFO Reading Strategies"},{"location":"fifo-queues/#fair-distribution-pgmqread_grouped_rr","text":"Interleaves messages across FIFO groups in layers: -- With groups A (5 messages), B (3 messages), C (2 messages) SELECT * FROM pgmq . read_grouped_rr ( 'queue' , 30 , 10 ); -- Returns (layered interleaving): A1, B1, C1, A2, B2, C2, A3, B3, A4, ... Best for: - Ensuring fair processing across all groups - Preventing starvation of groups with fewer messages - Load balancing across different workflows","title":"Fair Distribution (pgmq.read_grouped_rr())"},{"location":"fifo-queues/#throughput-optimization-pgmqread_grouped","text":"Attempts to fill the batch from the earliest group first: -- With groups A (5 messages), B (3 messages), C (2 messages) SELECT * FROM pgmq . read_grouped ( 'queue' , 30 , 10 ); -- Returns: 10 messages (5 from A + 3 from B + 2 from C) SELECT * FROM pgmq . read_grouped ( 'queue' , 30 , 3 ); -- Returns: 3 messages (all from group A) Best for: - Maximizing throughput for related messages - Processing workflows where batching related messages is beneficial - Mimicking AWS SQS FIFO behavior exactly","title":"Throughput Optimization (pgmq.read_grouped())"},{"location":"fifo-queues/#choosing-the-right-strategy","text":"Scenario Recommended Function Reason Multi-tenant processing read_grouped_rr() Ensures fair resource allocation Order processing pipeline read_grouped() Related orders processed together User activity streams read_grouped_rr() Prevents one active user from blocking others Document workflows read_grouped() Process all versions of a document together Financial transactions read_grouped() Batch related transactions for efficiency","title":"Choosing the Right Strategy"},{"location":"fifo-queues/#comparison-with-aws-sqs-fifo","text":"Feature PGMQ FIFO (RR) PGMQ read_grouped AWS SQS FIFO Group-based ordering \u2705 \u2705 \u2705 Parallel group processing \u2705 \u2705 \u2705 Batch retrieval strategy Fair (layered interleaving) Throughput-optimized Throughput-optimized Message deduplication \u274c \u274c \u2705 Throughput limits No limits No limits 300 TPS per group Exactly-once delivery \u274c \u274c \u2705 Cost Free Free Pay per request","title":"Comparison with AWS SQS FIFO"},{"location":"fifo-queues/#best-practices","text":"Choose appropriate group keys : Balance between ordering requirements and parallelism Create FIFO indexes : Improve performance for frequently used queues Monitor group distribution : Ensure even distribution across groups Handle failures gracefully : Implement retry logic and dead letter handling Test thoroughly : Verify ordering behavior under load Use meaningful group IDs : Make debugging and monitoring easier","title":"Best Practices"},{"location":"fifo-queues/#examples","text":"See examples/fifo_example.sql for comprehensive usage examples.","title":"Examples"},{"location":"api/sql/functions/","text":"Functions \u00b6 Sending Messages \u00b6 send \u00b6 Send a single message to a queue with optional headers and delay. Signatures: pgmq.send(queue_name text, msg jsonb) pgmq.send(queue_name text, msg jsonb, headers jsonb) pgmq.send(queue_name text, msg jsonb, delay integer) pgmq.send(queue_name text, msg jsonb, delay timestamp with time zone) pgmq.send(queue_name text, msg jsonb, headers jsonb, delay integer) pgmq.send(queue_name text, msg jsonb, headers jsonb, delay timestamp with time zone) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msg jsonb The message to send to the queue headers jsonb Optional message headers/metadata delay integer Time in seconds before the message becomes visible delay timestamp with time zone Timestamp when the message becomes visible Returns: The ID of the message that was added to the queue. Examples: -- Send a message select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' ); send ------ 1 -- Send a message with headers select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , '{\"trace_id\": \"abc123\"}' ); send ------ 2 -- Message with a delay of 5 seconds select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , 5 ); send ------ 3 -- Message readable from tomorrow select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , CURRENT_TIMESTAMP + INTERVAL '1 day' ); send ------ 4 -- Message with headers and delay select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , '{\"priority\": \"high\"}' , 10 ); send ------ 5 send_batch \u00b6 Send 1 or more messages to a queue with optional headers and delay. Signatures: pgmq.send_batch(queue_name text, msgs jsonb[]) pgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[]) pgmq.send_batch(queue_name text, msgs jsonb[], delay integer) pgmq.send_batch(queue_name text, msgs jsonb[], delay timestamp with time zone) pgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[], delay integer) pgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[], delay timestamp with time zone) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msgs jsonb[] Array of messages to send to the queue headers jsonb[] Array of headers for each message (must match msgs length, or can be omitted) delay integer Time in seconds before the messages become visible delay timestamp with time zone Timestamp when the messages become visible Returns: The IDs of the messages that were added to the queue. Examples: -- Send multiple messages select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [] ); send_batch ------------ 1 2 -- Send with headers for each message select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [], ARRAY [ '{\"trace_id\": \"abc\"}' , '{\"trace_id\": \"def\"}' ]:: jsonb [] ); send_batch ------------ 3 4 -- Messages with a delay of 5 seconds select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [], 5 ); send_batch ------------ 5 6 -- Messages readable from tomorrow select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [], CURRENT_TIMESTAMP + INTERVAL '1 day' ); send_batch ------------ 7 8 Reading Messages \u00b6 read \u00b6 Read 1 or more messages from a queue. The VT specifies the amount of time in seconds that the message will be invisible to other consumers after reading. pgmq.read( queue_name text, vt integer, qty integer, conditional jsonb DEFAULT '{}') RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue conditional jsonb Filters the messages by their json content. Defaults to '{}' - no filtering. This feature is experimental, and the API is subject to change in future releases Examples: Read messages from a queue select * from pgmq . read ( 'my_queue' , 10 , 2 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 1 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608922 - 05 | { \"hello\" : \"world_0\" } | 2 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"hello\" : \"world_1\" } | ( 2 rows ) Read a message from a queue with message filtering select * from pgmq . read ( 'my_queue' , 10 , 2 , '{\"hello\": \"world_1\"}' ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 2 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"hello\" : \"world_1\" } | ( 1 row ) read_with_poll \u00b6 Same as read(). Also provides convenient long-poll functionality. When there are no messages in the queue, the function call will wait for max_poll_seconds in duration before returning. If messages reach the queue during that duration, they will be read and returned immediately. pgmq.read_with_poll( queue_name text, vt integer, qty integer, max_poll_seconds integer DEFAULT 5, poll_interval_ms integer DEFAULT 100, conditional jsonb DEFAULT '{}' ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. conditional jsonb Filters the messages by their json content. Defaults to '{}' - no filtering. This feature is experimental, and the API is subject to change in future releases Example: select * from pgmq . read_with_poll ( 'my_queue' , 1 , 1 , 5 , 100 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+--------------------+--------- 1 | 1 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"hello\" : \"world\" } | read_grouped \u00b6 Read messages from a queue with AWS SQS FIFO-style batch retrieval behavior. This function attempts to return as many messages as possible from the same message group, filling the batch from the earliest available group first. Messages with the same FIFO group ID (specified in the x-pgmq-group header) will be processed in order. Messages without FIFO headers are treated as belonging to a default group. pgmq.read_grouped( queue_name text, vt integer, qty integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue FIFO Behavior (Fill from same group): - Messages with the same x-pgmq-group header value are processed in strict order - Only the oldest unprocessed message from each FIFO group can be read - The batch is filled preferentially from the earliest group (by oldest msg_id) - Messages from different FIFO groups can be processed in parallel - Messages without FIFO headers are treated as a single default group Examples: Send messages with FIFO grouping: -- Send messages to the same FIFO group select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 2}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 3}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user456\"}' ); -- Read with FIFO grouped ordering - tries to fill batch from earliest group select * from pgmq . read_grouped ( 'my_queue' , 10 , 5 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608922 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" } 2 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"order\" : 2 } | { \"x-pgmq-group\" : \"user123\" } 3 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"order\" : 3 } | { \"x-pgmq-group\" : \"user123\" } read_grouped_with_poll \u00b6 Same as read_grouped(). Also provides convenient long-poll functionality for FIFO queues. When there are no messages available that respect FIFO ordering, the function call will wait for max_poll_seconds in duration before returning. pgmq.read_grouped_with_poll( queue_name text, vt integer, qty integer, max_poll_seconds integer DEFAULT 5, poll_interval_ms integer DEFAULT 100 ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue. max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. Example: select * from pgmq . read_grouped_with_poll ( 'my_queue' , 10 , 5 , 5 , 100 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" } read_grouped_rr \u00b6 Read messages from a queue while respecting FIFO (First-In-First-Out) ordering within message groups and using round-robin interleaving across groups. Messages with the same FIFO group ID (specified in the x-pgmq-group header) will be processed in strict order. Messages without FIFO headers are treated as belonging to a default group. pgmq.read_grouped_rr( queue_name text, vt integer, qty integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue FIFO Behavior (Round Robin across groups): - Messages with the same x-pgmq-group header value are processed in strict order - Only the oldest unprocessed message from each FIFO group can be read - Messages from different FIFO groups can be processed in parallel - Messages without FIFO headers are treated as a single default group Examples: Send messages with FIFO grouping: -- Send messages to the same FIFO group select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 2}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user456\"}' ); -- Read with FIFO RR ordering - interleaves by group layers select * from pgmq . read_grouped_rr ( 'my_queue' , 10 , 5 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608922 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" } 3 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user456\" } read_grouped_rr_with_poll \u00b6 Same as read_grouped_rr(). Also provides convenient long-poll functionality for FIFO queues. When there are no messages available that respect FIFO ordering, the function call will wait for max_poll_seconds in duration before returning. pgmq.read_grouped_rr_with_poll( queue_name text, vt integer, qty integer, max_poll_seconds integer DEFAULT 5, poll_interval_ms integer DEFAULT 100 ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue. max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. Example: select * from pgmq . read_grouped_rr_with_poll ( 'my_queue' , 10 , 1 , 5 , 100 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" } pop \u00b6 Reads one or more messages from a queue and deletes them upon read. Note: utilization of pop() results in at-most-once delivery semantics if the consuming application does not guarantee processing of the message. pgmq.pop(queue_name text, qty integer DEFAULT 1) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue qty integer The number of messages to pop from the queue. Defaults to 1. Example: pgmq =# select * from pgmq . pop ( 'my_queue' ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+--------------------+--------- 1 | 2 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"hello\" : \"world\" } | Deleting/Archiving Messages \u00b6 delete (single) \u00b6 Deletes a single message from a queue. pgmq.delete (queue_name text, msg_id: bigint) RETURNS boolean Parameters: Parameter Type Description queue_name text The name of the queue msg_id bigint Message ID of the message to delete Example: select pgmq . delete ( 'my_queue' , 5 ); delete -------- t delete (batch) \u00b6 Delete one or many messages from a queue. pgmq.delete (queue_name text, msg_ids: bigint[]) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to delete Examples: Delete two messages that exist. select * from pgmq . delete ( 'my_queue' , ARRAY [ 2 , 3 ]); delete -------- 2 3 Delete two messages, one that exists and one that does not. Message 999 does not exist. select * from pgmq . delete ( 'my_queue' , ARRAY [ 6 , 999 ]); delete -------- 6 purge_queue \u00b6 Permanently deletes all messages in a queue. Returns the number of messages that were deleted. pgmq.purge_queue(queue_name text) RETURNS bigint Parameters: Parameter Type Description queue_name text The name of the queue Example: Purge the queue when it contains 8 messages; select * from pgmq . purge_queue ( 'my_queue' ); purge_queue ------------- 8 archive (single) \u00b6 Removes a single requested message from the specified queue and inserts it into the queue's archive. pgmq.archive(queue_name text, msg_id bigint) RETURNS boolean Parameters: Parameter Type Description queue_name text The name of the queue msg_id bigint Message ID of the message to archive Returns: Boolean value indicating success or failure of the operation. Note: Archived messages are stored in the archive table with an additional archived_at timestamp field indicating when the message was archived. Example; remove message with ID 1 from queue my_queue and archive it: SELECT * FROM pgmq . archive ( 'my_queue' , 1 ); archive --------- t archive (batch) \u00b6 Deletes a batch of requested messages from the specified queue and inserts them into the queue's archive. Returns an ARRAY of message ids that were successfully archived. pgmq.archive(queue_name text, msg_ids bigint[]) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to archive Examples: Delete messages with ID 1 and 2 from queue my_queue and move to the archive. SELECT * FROM pgmq . archive ( 'my_queue' , ARRAY [ 1 , 2 ]); archive --------- 1 2 Delete messages 4, which exists and 999, which does not exist. select * from pgmq . archive ( 'my_queue' , ARRAY [ 4 , 999 ]); archive --------- 4 Queue Management \u00b6 create \u00b6 Create a new queue. pgmq.create(queue_name text) RETURNS VOID Parameters: Parameter Type Description queue_name text The name of the queue (max 47 characters) Example: select from pgmq . create ( 'my_queue' ); create -------- create_non_partitioned \u00b6 Create a non-partitioned queue. This is the same as create() , but more explicit about the queue type. pgmq.create_non_partitioned(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue (max 47 characters) Example: select from pgmq . create_non_partitioned ( 'my_queue' ); create_non_partitioned ------------------------ create_partitioned \u00b6 Create a partitioned queue. Requires the pg_partman extension to be installed. pgmq.create_partitioned ( queue_name text, partition_interval text DEFAULT '10000'::text, retention_interval text DEFAULT '100000'::text ) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue (max 47 characters) partition_interval text Partition size - numeric value for msg_id-based partitioning (e.g., '10000'), or time interval for timestamp-based partitioning (e.g., '1 day'). Defaults to '10000'. retention_interval text How long/how many messages to retain before deleting old partitions. Same format as partition_interval. Defaults to '100000'. Example: Create a queue with 100,000 messages per partition, and will retain 10,000,000 messages on old partitions. Partitions greater than this will be deleted. select from pgmq . create_partitioned ( 'my_partitioned_queue' , '100000' , '10000000' ); create_partitioned -------------------- create_unlogged \u00b6 Creates an unlogged table. This is useful when write throughput is more important that durability. See Postgres documentation for unlogged tables for more information. pgmq.create_unlogged(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select pgmq . create_unlogged ( 'my_unlogged' ); create_unlogged ----------------- convert_archive_partitioned \u00b6 Convert an existing non-partitioned archive table to a partitioned one. Requires the pg_partman extension to be installed. This is useful for migrating queues to partitioned archives after they have been created. pgmq.convert_archive_partitioned( table_name text, partition_interval text DEFAULT '10000'::text, retention_interval text DEFAULT '100000'::text, leading_partition integer DEFAULT 10 ) RETURNS void Parameters: Parameter Type Description table_name text The name of the queue whose archive should be partitioned partition_interval text Partition size - numeric value for msg_id-based partitioning (e.g., '10000'), or time interval for timestamp-based partitioning (e.g., '1 day'). Defaults to '10000'. retention_interval text How long/how many messages to retain before deleting old partitions. Same format as partition_interval. Defaults to '100000'. leading_partition integer Number of partitions to create in advance. Defaults to 10. Note: This function renames the existing archive table to <table_name>_old and creates a new partitioned table. You may need to migrate data from the old table to the new one. Example: select from pgmq . convert_archive_partitioned ( 'my_queue' , '10000' , '100000' ); convert_archive_partitioned ----------------------------- detach_archive \u00b6 \u26a0\ufe0f DEPRECATED: This function is deprecated and is now a no-op (does nothing). It will be removed in PGMQ v2.0. Archive tables are no longer member objects of the extension. Drop the queue's archive table as a member of the PGMQ extension. Useful for preventing the queue's archive table from being drop when DROP EXTENSION pgmq is executed. This does not prevent the further archives() from appending to the archive table. pgmq.detach_archive(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select * from pgmq . detach_archive ( 'my_queue' ); detach_archive ---------------- drop_queue \u00b6 Deletes a queue and its archive table. pgmq.drop_queue(queue_name text) RETURNS boolean Parameters: Parameter Type Description queue_name text The name of the queue Note: There is a deprecated 2-parameter version drop_queue(queue_name, partitioned) that will be removed in PGMQ v2.0. Use the single-parameter version instead, which automatically detects whether the queue is partitioned. Example: select * from pgmq . drop_queue ( 'my_unlogged' ); drop_queue ------------ t Utilities \u00b6 set_vt (single) \u00b6 Sets the visibility timeout of a message to a specified time duration in the future. Returns the record of the message that was updated. pgmq.set_vt( queue_name text, msg_id bigint, vt integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue msg_id bigint ID of the message to set visibility time vt integer Duration from now, in seconds, that the message's VT should be set to Example: Set the visibility timeout of message 1 to 30 seconds from now. select * from pgmq . set_vt ( 'my_queue' , 1 , 30 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 1 | 0 | 2023 - 10 - 28 19 : 42 : 21 . 778741 - 05 | 2023 - 10 - 28 19 : 59 : 34 . 286462 - 05 | { \"hello\" : \"world_0\" } | set_vt (batch) \u00b6 Sets the visibility timeout of multiple messages to a specified time duration in the future. Returns the records of the messages that were updated. pgmq.set_vt( queue_name text, msg_ids bigint[], vt integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to set visibility time vt integer Duration from now, in seconds, that the messages' VT should be set to Example: Set the visibility timeout of messages 1 and 2 to 60 seconds from now. select * from pgmq . set_vt ( 'my_queue' , ARRAY [ 1 , 2 ], 60 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 1 | 0 | 2023 - 10 - 28 19 : 42 : 21 . 778741 - 05 | 2023 - 10 - 28 19 : 59 : 34 . 286462 - 05 | { \"hello\" : \"world_0\" } | 2 | 1 | 2023 - 10 - 28 19 : 42 : 22 . 123456 - 05 | 2023 - 10 - 28 19 : 59 : 34 . 286501 - 05 | { \"hello\" : \"world_1\" } | list_queues \u00b6 List all the queues that currently exist. pgmq . list_queues () RETURNS SETOF pgmq . queue_record Example: select * from pgmq . list_queues (); queue_name | created_at | is_partitioned | is_unlogged ----------------------+-------------------------------+----------------+------------- my_queue | 2023 - 10 - 28 14 : 13 : 17 . 092576 - 05 | f | f my_partitioned_queue | 2023 - 10 - 28 19 : 47 : 37 . 098692 - 05 | t | f my_unlogged | 2023 - 10 - 28 20 : 02 : 30 . 976109 - 05 | f | t metrics \u00b6 Get metrics for a specific queue. pgmq.metrics(queue_name text) RETURNS pgmq.metrics_result Parameters: Parameter Type Description queue_name text The name of the queue Returns: Attribute Type Description queue_name text The name of the queue queue_length bigint Number of messages currently in the queue newest_msg_age_sec integer | null Age of the newest message in the queue, in seconds oldest_msg_age_sec integer | null Age of the oldest message in the queue, in seconds total_messages bigint Total number of messages that have passed through the queue over all time scrape_time timestamp with time zone The current timestamp queue_visible_length bigint Number of messages currently visible (vt <= now) Example: select * from pgmq . metrics ( 'my_queue' ); queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages | scrape_time ------------+--------------+--------------------+--------------------+----------------+------------------------------- my_queue | 16 | 2445 | 2447 | 35 | 2023 - 10 - 28 20 : 23 : 08 . 406259 - 05 metrics_all \u00b6 Get metrics for all existing queues. pgmq.metrics_all() RETURNS SETOF pgmq.metrics_result Returns: Attribute Type Description queue_name text The name of the queue queue_length bigint Number of messages currently in the queue newest_msg_age_sec integer | null Age of the newest message in the queue, in seconds oldest_msg_age_sec integer | null Age of the oldest message in the queue, in seconds total_messages bigint Total number of messages that have passed through the queue over all time scrape_time timestamp with time zone The current timestamp queue_visible_length bigint Number of messages currently visible (vt <= now) select * from pgmq . metrics_all (); queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages | scrape_time ----------------------+--------------+--------------------+--------------------+----------------+------------------------------- my_queue | 16 | 2563 | 2565 | 35 | 2023 - 10 - 28 20 : 25 : 07 . 016413 - 05 my_partitioned_queue | 1 | 11 | 11 | 1 | 2023 - 10 - 28 20 : 25 : 07 . 016413 - 05 my_unlogged | 1 | 3 | 3 | 1 | 2023 - 10 - 28 20 : 25 : 07 . 016413 - 05 enable_notify_insert \u00b6 Enable PostgreSQL NOTIFY triggers for a queue with optional throttling. When enabled, a notification is sent on the channel pgmq.<queue_table>.INSERT every time a message is inserted (subject to throttling). This allows applications to use LISTEN to be notified immediately when new messages arrive, instead of polling. pgmq.enable_notify_insert(queue_name text, throttle_interval_ms integer DEFAULT 250) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue throttle_interval_ms integer Minimum milliseconds between notifications. Set to 0 to disable throttling. Defaults to 250. Notes: The notification channel will be named pgmq.q_<queue_name>.INSERT where q_<queue_name> is the internal table name. Throttling behavior : Throttling prevents excessive notifications during high-volume inserts. When multiple messages are inserted rapidly, only one notification per throttle interval will be sent. This protects your system from notification overhead when message volume is high. When to use notifications : Notifications are most valuable for queues with sporadic or low-volume traffic. During high-volume periods, consumers can continuously poll and expect work to be present. However, when there are longer gaps between messages, notifications allow the consumer to wait idle and only poll when it receives a notification, significantly reducing unnecessary polling overhead. The throttling feature ensures that during burst traffic, you don't create excessive notifications while still maintaining the notification behavior during low-volume periods. Examples: -- Enable notifications with default 250ms throttling select pgmq . enable_notify_insert ( 'my_queue' ); enable_notify_insert ---------------------- -- Enable notifications with custom 500ms throttling select pgmq . enable_notify_insert ( 'my_queue' , 500 ); enable_notify_insert ---------------------- -- Enable notifications with no throttling (0ms) select pgmq . enable_notify_insert ( 'my_queue' , 0 ); enable_notify_insert ---------------------- -- In another session, listen for notifications: -- LISTEN \"pgmq.q_my_queue.INSERT\"; Changing throttling after enabling notifications: You can modify the throttling interval for an existing queue by directly updating the pgmq.notify_insert_throttle table: -- Change throttling to 1000ms (1 second) UPDATE pgmq . notify_insert_throttle SET throttle_interval_ms = 1000 WHERE queue_name = 'my_queue' ; -- Disable throttling (set to 0ms) UPDATE pgmq . notify_insert_throttle SET throttle_interval_ms = 0 WHERE queue_name = 'my_queue' ; -- View current throttle settings for all queues SELECT queue_name , throttle_interval_ms , last_notified_at FROM pgmq . notify_insert_throttle ; disable_notify_insert \u00b6 Disable PostgreSQL NOTIFY triggers for a queue that were enabled with enable_notify_insert() . pgmq.disable_notify_insert(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select pgmq . disable_notify_insert ( 'my_queue' ); disable_notify_insert ----------------------- create_fifo_index \u00b6 Creates a GIN index on the headers column for a specific queue to improve FIFO read performance. This is recommended when using FIFO functionality frequently on a queue. pgmq.create_fifo_index(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select pgmq . create_fifo_index ( 'my_queue' ); create_fifo_index ------------------- create_fifo_indexes_all \u00b6 Creates FIFO indexes on all existing queues. This is a convenience function to optimize all queues for FIFO operations. pgmq.create_fifo_indexes_all() RETURNS void Example: select pgmq . create_fifo_indexes_all (); create_fifo_indexes_all -------------------------","title":"Functions"},{"location":"api/sql/functions/#functions","text":"","title":"Functions"},{"location":"api/sql/functions/#sending-messages","text":"","title":"Sending Messages"},{"location":"api/sql/functions/#send","text":"Send a single message to a queue with optional headers and delay. Signatures: pgmq.send(queue_name text, msg jsonb) pgmq.send(queue_name text, msg jsonb, headers jsonb) pgmq.send(queue_name text, msg jsonb, delay integer) pgmq.send(queue_name text, msg jsonb, delay timestamp with time zone) pgmq.send(queue_name text, msg jsonb, headers jsonb, delay integer) pgmq.send(queue_name text, msg jsonb, headers jsonb, delay timestamp with time zone) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msg jsonb The message to send to the queue headers jsonb Optional message headers/metadata delay integer Time in seconds before the message becomes visible delay timestamp with time zone Timestamp when the message becomes visible Returns: The ID of the message that was added to the queue. Examples: -- Send a message select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' ); send ------ 1 -- Send a message with headers select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , '{\"trace_id\": \"abc123\"}' ); send ------ 2 -- Message with a delay of 5 seconds select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , 5 ); send ------ 3 -- Message readable from tomorrow select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , CURRENT_TIMESTAMP + INTERVAL '1 day' ); send ------ 4 -- Message with headers and delay select * from pgmq . send ( 'my_queue' , '{\"hello\": \"world\"}' , '{\"priority\": \"high\"}' , 10 ); send ------ 5","title":"send"},{"location":"api/sql/functions/#send_batch","text":"Send 1 or more messages to a queue with optional headers and delay. Signatures: pgmq.send_batch(queue_name text, msgs jsonb[]) pgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[]) pgmq.send_batch(queue_name text, msgs jsonb[], delay integer) pgmq.send_batch(queue_name text, msgs jsonb[], delay timestamp with time zone) pgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[], delay integer) pgmq.send_batch(queue_name text, msgs jsonb[], headers jsonb[], delay timestamp with time zone) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msgs jsonb[] Array of messages to send to the queue headers jsonb[] Array of headers for each message (must match msgs length, or can be omitted) delay integer Time in seconds before the messages become visible delay timestamp with time zone Timestamp when the messages become visible Returns: The IDs of the messages that were added to the queue. Examples: -- Send multiple messages select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [] ); send_batch ------------ 1 2 -- Send with headers for each message select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [], ARRAY [ '{\"trace_id\": \"abc\"}' , '{\"trace_id\": \"def\"}' ]:: jsonb [] ); send_batch ------------ 3 4 -- Messages with a delay of 5 seconds select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [], 5 ); send_batch ------------ 5 6 -- Messages readable from tomorrow select * from pgmq . send_batch ( 'my_queue' , ARRAY [ '{\"hello\": \"world_0\"}' , '{\"hello\": \"world_1\"}' ]:: jsonb [], CURRENT_TIMESTAMP + INTERVAL '1 day' ); send_batch ------------ 7 8","title":"send_batch"},{"location":"api/sql/functions/#reading-messages","text":"","title":"Reading Messages"},{"location":"api/sql/functions/#read","text":"Read 1 or more messages from a queue. The VT specifies the amount of time in seconds that the message will be invisible to other consumers after reading. pgmq.read( queue_name text, vt integer, qty integer, conditional jsonb DEFAULT '{}') RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue conditional jsonb Filters the messages by their json content. Defaults to '{}' - no filtering. This feature is experimental, and the API is subject to change in future releases Examples: Read messages from a queue select * from pgmq . read ( 'my_queue' , 10 , 2 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 1 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608922 - 05 | { \"hello\" : \"world_0\" } | 2 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"hello\" : \"world_1\" } | ( 2 rows ) Read a message from a queue with message filtering select * from pgmq . read ( 'my_queue' , 10 , 2 , '{\"hello\": \"world_1\"}' ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 2 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"hello\" : \"world_1\" } | ( 1 row )","title":"read"},{"location":"api/sql/functions/#read_with_poll","text":"Same as read(). Also provides convenient long-poll functionality. When there are no messages in the queue, the function call will wait for max_poll_seconds in duration before returning. If messages reach the queue during that duration, they will be read and returned immediately. pgmq.read_with_poll( queue_name text, vt integer, qty integer, max_poll_seconds integer DEFAULT 5, poll_interval_ms integer DEFAULT 100, conditional jsonb DEFAULT '{}' ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. conditional jsonb Filters the messages by their json content. Defaults to '{}' - no filtering. This feature is experimental, and the API is subject to change in future releases Example: select * from pgmq . read_with_poll ( 'my_queue' , 1 , 1 , 5 , 100 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+--------------------+--------- 1 | 1 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"hello\" : \"world\" } |","title":"read_with_poll"},{"location":"api/sql/functions/#read_grouped","text":"Read messages from a queue with AWS SQS FIFO-style batch retrieval behavior. This function attempts to return as many messages as possible from the same message group, filling the batch from the earliest available group first. Messages with the same FIFO group ID (specified in the x-pgmq-group header) will be processed in order. Messages without FIFO headers are treated as belonging to a default group. pgmq.read_grouped( queue_name text, vt integer, qty integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue FIFO Behavior (Fill from same group): - Messages with the same x-pgmq-group header value are processed in strict order - Only the oldest unprocessed message from each FIFO group can be read - The batch is filled preferentially from the earliest group (by oldest msg_id) - Messages from different FIFO groups can be processed in parallel - Messages without FIFO headers are treated as a single default group Examples: Send messages with FIFO grouping: -- Send messages to the same FIFO group select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 2}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 3}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user456\"}' ); -- Read with FIFO grouped ordering - tries to fill batch from earliest group select * from pgmq . read_grouped ( 'my_queue' , 10 , 5 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608922 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" } 2 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"order\" : 2 } | { \"x-pgmq-group\" : \"user123\" } 3 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"order\" : 3 } | { \"x-pgmq-group\" : \"user123\" }","title":"read_grouped"},{"location":"api/sql/functions/#read_grouped_with_poll","text":"Same as read_grouped(). Also provides convenient long-poll functionality for FIFO queues. When there are no messages available that respect FIFO ordering, the function call will wait for max_poll_seconds in duration before returning. pgmq.read_grouped_with_poll( queue_name text, vt integer, qty integer, max_poll_seconds integer DEFAULT 5, poll_interval_ms integer DEFAULT 100 ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue. max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. Example: select * from pgmq . read_grouped_with_poll ( 'my_queue' , 10 , 5 , 5 , 100 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" }","title":"read_grouped_with_poll"},{"location":"api/sql/functions/#read_grouped_rr","text":"Read messages from a queue while respecting FIFO (First-In-First-Out) ordering within message groups and using round-robin interleaving across groups. Messages with the same FIFO group ID (specified in the x-pgmq-group header) will be processed in strict order. Messages without FIFO headers are treated as belonging to a default group. pgmq.read_grouped_rr( queue_name text, vt integer, qty integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading qty integer The number of messages to read from the queue FIFO Behavior (Round Robin across groups): - Messages with the same x-pgmq-group header value are processed in strict order - Only the oldest unprocessed message from each FIFO group can be read - Messages from different FIFO groups can be processed in parallel - Messages without FIFO headers are treated as a single default group Examples: Send messages with FIFO grouping: -- Send messages to the same FIFO group select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 2}' , '{\"x-pgmq-group\": \"user123\"}' ); select pgmq . send ( 'my_queue' , '{\"order\": 1}' , '{\"x-pgmq-group\": \"user456\"}' ); -- Read with FIFO RR ordering - interleaves by group layers select * from pgmq . read_grouped_rr ( 'my_queue' , 10 , 5 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608922 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" } 3 | 1 | 2023 - 10 - 28 19 : 14 : 47 . 356595 - 05 | 2023 - 10 - 28 19 : 17 : 08 . 608974 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user456\" }","title":"read_grouped_rr"},{"location":"api/sql/functions/#read_grouped_rr_with_poll","text":"Same as read_grouped_rr(). Also provides convenient long-poll functionality for FIFO queues. When there are no messages available that respect FIFO ordering, the function call will wait for max_poll_seconds in duration before returning. pgmq.read_grouped_rr_with_poll( queue_name text, vt integer, qty integer, max_poll_seconds integer DEFAULT 5, poll_interval_ms integer DEFAULT 100 ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue vt integer Time in seconds that the message become invisible after reading. qty integer The number of messages to read from the queue. max_poll_seconds integer Time in seconds to wait for new messages to reach the queue. Defaults to 5. poll_interval_ms integer Milliseconds between the internal poll operations. Defaults to 100. Example: select * from pgmq . read_grouped_rr_with_poll ( 'my_queue' , 10 , 1 , 5 , 100 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+-----------------+--------------------------- 1 | 1 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"order\" : 1 } | { \"x-pgmq-group\" : \"user123\" }","title":"read_grouped_rr_with_poll"},{"location":"api/sql/functions/#pop","text":"Reads one or more messages from a queue and deletes them upon read. Note: utilization of pop() results in at-most-once delivery semantics if the consuming application does not guarantee processing of the message. pgmq.pop(queue_name text, qty integer DEFAULT 1) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue qty integer The number of messages to pop from the queue. Defaults to 1. Example: pgmq =# select * from pgmq . pop ( 'my_queue' ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+--------------------+--------- 1 | 2 | 2023 - 10 - 28 19 : 09 : 09 . 177756 - 05 | 2023 - 10 - 28 19 : 27 : 00 . 337929 - 05 | { \"hello\" : \"world\" } |","title":"pop"},{"location":"api/sql/functions/#deletingarchiving-messages","text":"","title":"Deleting/Archiving Messages"},{"location":"api/sql/functions/#delete-single","text":"Deletes a single message from a queue. pgmq.delete (queue_name text, msg_id: bigint) RETURNS boolean Parameters: Parameter Type Description queue_name text The name of the queue msg_id bigint Message ID of the message to delete Example: select pgmq . delete ( 'my_queue' , 5 ); delete -------- t","title":"delete (single)"},{"location":"api/sql/functions/#delete-batch","text":"Delete one or many messages from a queue. pgmq.delete (queue_name text, msg_ids: bigint[]) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to delete Examples: Delete two messages that exist. select * from pgmq . delete ( 'my_queue' , ARRAY [ 2 , 3 ]); delete -------- 2 3 Delete two messages, one that exists and one that does not. Message 999 does not exist. select * from pgmq . delete ( 'my_queue' , ARRAY [ 6 , 999 ]); delete -------- 6","title":"delete (batch)"},{"location":"api/sql/functions/#purge_queue","text":"Permanently deletes all messages in a queue. Returns the number of messages that were deleted. pgmq.purge_queue(queue_name text) RETURNS bigint Parameters: Parameter Type Description queue_name text The name of the queue Example: Purge the queue when it contains 8 messages; select * from pgmq . purge_queue ( 'my_queue' ); purge_queue ------------- 8","title":"purge_queue"},{"location":"api/sql/functions/#archive-single","text":"Removes a single requested message from the specified queue and inserts it into the queue's archive. pgmq.archive(queue_name text, msg_id bigint) RETURNS boolean Parameters: Parameter Type Description queue_name text The name of the queue msg_id bigint Message ID of the message to archive Returns: Boolean value indicating success or failure of the operation. Note: Archived messages are stored in the archive table with an additional archived_at timestamp field indicating when the message was archived. Example; remove message with ID 1 from queue my_queue and archive it: SELECT * FROM pgmq . archive ( 'my_queue' , 1 ); archive --------- t","title":"archive (single)"},{"location":"api/sql/functions/#archive-batch","text":"Deletes a batch of requested messages from the specified queue and inserts them into the queue's archive. Returns an ARRAY of message ids that were successfully archived. pgmq.archive(queue_name text, msg_ids bigint[]) RETURNS SETOF bigint Parameters: Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to archive Examples: Delete messages with ID 1 and 2 from queue my_queue and move to the archive. SELECT * FROM pgmq . archive ( 'my_queue' , ARRAY [ 1 , 2 ]); archive --------- 1 2 Delete messages 4, which exists and 999, which does not exist. select * from pgmq . archive ( 'my_queue' , ARRAY [ 4 , 999 ]); archive --------- 4","title":"archive (batch)"},{"location":"api/sql/functions/#queue-management","text":"","title":"Queue Management"},{"location":"api/sql/functions/#create","text":"Create a new queue. pgmq.create(queue_name text) RETURNS VOID Parameters: Parameter Type Description queue_name text The name of the queue (max 47 characters) Example: select from pgmq . create ( 'my_queue' ); create --------","title":"create"},{"location":"api/sql/functions/#create_non_partitioned","text":"Create a non-partitioned queue. This is the same as create() , but more explicit about the queue type. pgmq.create_non_partitioned(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue (max 47 characters) Example: select from pgmq . create_non_partitioned ( 'my_queue' ); create_non_partitioned ------------------------","title":"create_non_partitioned"},{"location":"api/sql/functions/#create_partitioned","text":"Create a partitioned queue. Requires the pg_partman extension to be installed. pgmq.create_partitioned ( queue_name text, partition_interval text DEFAULT '10000'::text, retention_interval text DEFAULT '100000'::text ) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue (max 47 characters) partition_interval text Partition size - numeric value for msg_id-based partitioning (e.g., '10000'), or time interval for timestamp-based partitioning (e.g., '1 day'). Defaults to '10000'. retention_interval text How long/how many messages to retain before deleting old partitions. Same format as partition_interval. Defaults to '100000'. Example: Create a queue with 100,000 messages per partition, and will retain 10,000,000 messages on old partitions. Partitions greater than this will be deleted. select from pgmq . create_partitioned ( 'my_partitioned_queue' , '100000' , '10000000' ); create_partitioned --------------------","title":"create_partitioned"},{"location":"api/sql/functions/#create_unlogged","text":"Creates an unlogged table. This is useful when write throughput is more important that durability. See Postgres documentation for unlogged tables for more information. pgmq.create_unlogged(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select pgmq . create_unlogged ( 'my_unlogged' ); create_unlogged -----------------","title":"create_unlogged"},{"location":"api/sql/functions/#convert_archive_partitioned","text":"Convert an existing non-partitioned archive table to a partitioned one. Requires the pg_partman extension to be installed. This is useful for migrating queues to partitioned archives after they have been created. pgmq.convert_archive_partitioned( table_name text, partition_interval text DEFAULT '10000'::text, retention_interval text DEFAULT '100000'::text, leading_partition integer DEFAULT 10 ) RETURNS void Parameters: Parameter Type Description table_name text The name of the queue whose archive should be partitioned partition_interval text Partition size - numeric value for msg_id-based partitioning (e.g., '10000'), or time interval for timestamp-based partitioning (e.g., '1 day'). Defaults to '10000'. retention_interval text How long/how many messages to retain before deleting old partitions. Same format as partition_interval. Defaults to '100000'. leading_partition integer Number of partitions to create in advance. Defaults to 10. Note: This function renames the existing archive table to <table_name>_old and creates a new partitioned table. You may need to migrate data from the old table to the new one. Example: select from pgmq . convert_archive_partitioned ( 'my_queue' , '10000' , '100000' ); convert_archive_partitioned -----------------------------","title":"convert_archive_partitioned"},{"location":"api/sql/functions/#detach_archive","text":"\u26a0\ufe0f DEPRECATED: This function is deprecated and is now a no-op (does nothing). It will be removed in PGMQ v2.0. Archive tables are no longer member objects of the extension. Drop the queue's archive table as a member of the PGMQ extension. Useful for preventing the queue's archive table from being drop when DROP EXTENSION pgmq is executed. This does not prevent the further archives() from appending to the archive table. pgmq.detach_archive(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select * from pgmq . detach_archive ( 'my_queue' ); detach_archive ----------------","title":"detach_archive"},{"location":"api/sql/functions/#drop_queue","text":"Deletes a queue and its archive table. pgmq.drop_queue(queue_name text) RETURNS boolean Parameters: Parameter Type Description queue_name text The name of the queue Note: There is a deprecated 2-parameter version drop_queue(queue_name, partitioned) that will be removed in PGMQ v2.0. Use the single-parameter version instead, which automatically detects whether the queue is partitioned. Example: select * from pgmq . drop_queue ( 'my_unlogged' ); drop_queue ------------ t","title":"drop_queue"},{"location":"api/sql/functions/#utilities","text":"","title":"Utilities"},{"location":"api/sql/functions/#set_vt-single","text":"Sets the visibility timeout of a message to a specified time duration in the future. Returns the record of the message that was updated. pgmq.set_vt( queue_name text, msg_id bigint, vt integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue msg_id bigint ID of the message to set visibility time vt integer Duration from now, in seconds, that the message's VT should be set to Example: Set the visibility timeout of message 1 to 30 seconds from now. select * from pgmq . set_vt ( 'my_queue' , 1 , 30 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 1 | 0 | 2023 - 10 - 28 19 : 42 : 21 . 778741 - 05 | 2023 - 10 - 28 19 : 59 : 34 . 286462 - 05 | { \"hello\" : \"world_0\" } |","title":"set_vt (single)"},{"location":"api/sql/functions/#set_vt-batch","text":"Sets the visibility timeout of multiple messages to a specified time duration in the future. Returns the records of the messages that were updated. pgmq.set_vt( queue_name text, msg_ids bigint[], vt integer ) RETURNS SETOF pgmq.message_record Parameters: Parameter Type Description queue_name text The name of the queue msg_ids bigint[] Array of message IDs to set visibility time vt integer Duration from now, in seconds, that the messages' VT should be set to Example: Set the visibility timeout of messages 1 and 2 to 60 seconds from now. select * from pgmq . set_vt ( 'my_queue' , ARRAY [ 1 , 2 ], 60 ); msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+----------------------+--------- 1 | 0 | 2023 - 10 - 28 19 : 42 : 21 . 778741 - 05 | 2023 - 10 - 28 19 : 59 : 34 . 286462 - 05 | { \"hello\" : \"world_0\" } | 2 | 1 | 2023 - 10 - 28 19 : 42 : 22 . 123456 - 05 | 2023 - 10 - 28 19 : 59 : 34 . 286501 - 05 | { \"hello\" : \"world_1\" } |","title":"set_vt (batch)"},{"location":"api/sql/functions/#list_queues","text":"List all the queues that currently exist. pgmq . list_queues () RETURNS SETOF pgmq . queue_record Example: select * from pgmq . list_queues (); queue_name | created_at | is_partitioned | is_unlogged ----------------------+-------------------------------+----------------+------------- my_queue | 2023 - 10 - 28 14 : 13 : 17 . 092576 - 05 | f | f my_partitioned_queue | 2023 - 10 - 28 19 : 47 : 37 . 098692 - 05 | t | f my_unlogged | 2023 - 10 - 28 20 : 02 : 30 . 976109 - 05 | f | t","title":"list_queues"},{"location":"api/sql/functions/#metrics","text":"Get metrics for a specific queue. pgmq.metrics(queue_name text) RETURNS pgmq.metrics_result Parameters: Parameter Type Description queue_name text The name of the queue Returns: Attribute Type Description queue_name text The name of the queue queue_length bigint Number of messages currently in the queue newest_msg_age_sec integer | null Age of the newest message in the queue, in seconds oldest_msg_age_sec integer | null Age of the oldest message in the queue, in seconds total_messages bigint Total number of messages that have passed through the queue over all time scrape_time timestamp with time zone The current timestamp queue_visible_length bigint Number of messages currently visible (vt <= now) Example: select * from pgmq . metrics ( 'my_queue' ); queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages | scrape_time ------------+--------------+--------------------+--------------------+----------------+------------------------------- my_queue | 16 | 2445 | 2447 | 35 | 2023 - 10 - 28 20 : 23 : 08 . 406259 - 05","title":"metrics"},{"location":"api/sql/functions/#metrics_all","text":"Get metrics for all existing queues. pgmq.metrics_all() RETURNS SETOF pgmq.metrics_result Returns: Attribute Type Description queue_name text The name of the queue queue_length bigint Number of messages currently in the queue newest_msg_age_sec integer | null Age of the newest message in the queue, in seconds oldest_msg_age_sec integer | null Age of the oldest message in the queue, in seconds total_messages bigint Total number of messages that have passed through the queue over all time scrape_time timestamp with time zone The current timestamp queue_visible_length bigint Number of messages currently visible (vt <= now) select * from pgmq . metrics_all (); queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages | scrape_time ----------------------+--------------+--------------------+--------------------+----------------+------------------------------- my_queue | 16 | 2563 | 2565 | 35 | 2023 - 10 - 28 20 : 25 : 07 . 016413 - 05 my_partitioned_queue | 1 | 11 | 11 | 1 | 2023 - 10 - 28 20 : 25 : 07 . 016413 - 05 my_unlogged | 1 | 3 | 3 | 1 | 2023 - 10 - 28 20 : 25 : 07 . 016413 - 05","title":"metrics_all"},{"location":"api/sql/functions/#enable_notify_insert","text":"Enable PostgreSQL NOTIFY triggers for a queue with optional throttling. When enabled, a notification is sent on the channel pgmq.<queue_table>.INSERT every time a message is inserted (subject to throttling). This allows applications to use LISTEN to be notified immediately when new messages arrive, instead of polling. pgmq.enable_notify_insert(queue_name text, throttle_interval_ms integer DEFAULT 250) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue throttle_interval_ms integer Minimum milliseconds between notifications. Set to 0 to disable throttling. Defaults to 250. Notes: The notification channel will be named pgmq.q_<queue_name>.INSERT where q_<queue_name> is the internal table name. Throttling behavior : Throttling prevents excessive notifications during high-volume inserts. When multiple messages are inserted rapidly, only one notification per throttle interval will be sent. This protects your system from notification overhead when message volume is high. When to use notifications : Notifications are most valuable for queues with sporadic or low-volume traffic. During high-volume periods, consumers can continuously poll and expect work to be present. However, when there are longer gaps between messages, notifications allow the consumer to wait idle and only poll when it receives a notification, significantly reducing unnecessary polling overhead. The throttling feature ensures that during burst traffic, you don't create excessive notifications while still maintaining the notification behavior during low-volume periods. Examples: -- Enable notifications with default 250ms throttling select pgmq . enable_notify_insert ( 'my_queue' ); enable_notify_insert ---------------------- -- Enable notifications with custom 500ms throttling select pgmq . enable_notify_insert ( 'my_queue' , 500 ); enable_notify_insert ---------------------- -- Enable notifications with no throttling (0ms) select pgmq . enable_notify_insert ( 'my_queue' , 0 ); enable_notify_insert ---------------------- -- In another session, listen for notifications: -- LISTEN \"pgmq.q_my_queue.INSERT\"; Changing throttling after enabling notifications: You can modify the throttling interval for an existing queue by directly updating the pgmq.notify_insert_throttle table: -- Change throttling to 1000ms (1 second) UPDATE pgmq . notify_insert_throttle SET throttle_interval_ms = 1000 WHERE queue_name = 'my_queue' ; -- Disable throttling (set to 0ms) UPDATE pgmq . notify_insert_throttle SET throttle_interval_ms = 0 WHERE queue_name = 'my_queue' ; -- View current throttle settings for all queues SELECT queue_name , throttle_interval_ms , last_notified_at FROM pgmq . notify_insert_throttle ;","title":"enable_notify_insert"},{"location":"api/sql/functions/#disable_notify_insert","text":"Disable PostgreSQL NOTIFY triggers for a queue that were enabled with enable_notify_insert() . pgmq.disable_notify_insert(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select pgmq . disable_notify_insert ( 'my_queue' ); disable_notify_insert -----------------------","title":"disable_notify_insert"},{"location":"api/sql/functions/#create_fifo_index","text":"Creates a GIN index on the headers column for a specific queue to improve FIFO read performance. This is recommended when using FIFO functionality frequently on a queue. pgmq.create_fifo_index(queue_name text) RETURNS void Parameters: Parameter Type Description queue_name text The name of the queue Example: select pgmq . create_fifo_index ( 'my_queue' ); create_fifo_index -------------------","title":"create_fifo_index"},{"location":"api/sql/functions/#create_fifo_indexes_all","text":"Creates FIFO indexes on all existing queues. This is a convenience function to optimize all queues for FIFO operations. pgmq.create_fifo_indexes_all() RETURNS void Example: select pgmq . create_fifo_indexes_all (); create_fifo_indexes_all -------------------------","title":"create_fifo_indexes_all"},{"location":"api/sql/types/","text":"Types \u00b6 message_record \u00b6 The complete representation of a message in a queue. Attribute Name Type Description msg_id bigint Unique ID of the message read_ct integer Number of times the message has been read. Increments on read(). enqueued_at timestamp with time zone time that the message was inserted into the queue vt timestamp with time zone Timestamp when the message will become available for consumers to read message jsonb The message payload headers jsonb Optional message headers/metadata Example: msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+---------------------+-------------------------- 1 | 1 | 2023-10-28 19:06:19.941509-05 | 2023-10-28 19:06:27.419392-05 | {\"hello\": \"world\"} | {\"trace_id\": \"abc123\"} queue_record \u00b6 Represents metadata about a queue. Attribute Name Type Description queue_name varchar Name of the queue is_partitioned boolean Whether the queue is partitioned is_unlogged boolean Whether the queue is unlogged (higher performance, less durability) created_at timestamp with time zone When the queue was created Example: queue_name | created_at | is_partitioned | is_unlogged ----------------------+-------------------------------+----------------+------------- my_queue | 2023-10-28 14:13:17.092576-05 | f | f metrics_result \u00b6 Contains metrics and statistics for a queue. Attribute Name Type Description queue_name text Name of the queue queue_length bigint Total number of messages currently in the queue newest_msg_age_sec integer Age of the newest message in seconds (null if queue is empty) oldest_msg_age_sec integer Age of the oldest message in seconds (null if queue is empty) total_messages bigint Total number of messages that have ever been in the queue scrape_time timestamp with time zone Timestamp when metrics were collected queue_visible_length bigint Number of messages currently visible (vt <= now) Example: queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages | scrape_time | queue_visible_length ------------+--------------+--------------------+--------------------+----------------+-------------------------------+--------------------- my_queue | 16 | 2445 | 2447 | 35 | 2023-10-28 20:23:08.406259-05 | 12","title":"Types"},{"location":"api/sql/types/#types","text":"","title":"Types"},{"location":"api/sql/types/#message_record","text":"The complete representation of a message in a queue. Attribute Name Type Description msg_id bigint Unique ID of the message read_ct integer Number of times the message has been read. Increments on read(). enqueued_at timestamp with time zone time that the message was inserted into the queue vt timestamp with time zone Timestamp when the message will become available for consumers to read message jsonb The message payload headers jsonb Optional message headers/metadata Example: msg_id | read_ct | enqueued_at | vt | message | headers --------+---------+-------------------------------+-------------------------------+---------------------+-------------------------- 1 | 1 | 2023-10-28 19:06:19.941509-05 | 2023-10-28 19:06:27.419392-05 | {\"hello\": \"world\"} | {\"trace_id\": \"abc123\"}","title":"message_record"},{"location":"api/sql/types/#queue_record","text":"Represents metadata about a queue. Attribute Name Type Description queue_name varchar Name of the queue is_partitioned boolean Whether the queue is partitioned is_unlogged boolean Whether the queue is unlogged (higher performance, less durability) created_at timestamp with time zone When the queue was created Example: queue_name | created_at | is_partitioned | is_unlogged ----------------------+-------------------------------+----------------+------------- my_queue | 2023-10-28 14:13:17.092576-05 | f | f","title":"queue_record"},{"location":"api/sql/types/#metrics_result","text":"Contains metrics and statistics for a queue. Attribute Name Type Description queue_name text Name of the queue queue_length bigint Total number of messages currently in the queue newest_msg_age_sec integer Age of the newest message in seconds (null if queue is empty) oldest_msg_age_sec integer Age of the oldest message in seconds (null if queue is empty) total_messages bigint Total number of messages that have ever been in the queue scrape_time timestamp with time zone Timestamp when metrics were collected queue_visible_length bigint Number of messages currently visible (vt <= now) Example: queue_name | queue_length | newest_msg_age_sec | oldest_msg_age_sec | total_messages | scrape_time | queue_visible_length ------------+--------------+--------------------+--------------------+----------------+-------------------------------+--------------------- my_queue | 16 | 2445 | 2447 | 35 | 2023-10-28 20:23:08.406259-05 | 12","title":"metrics_result"}]}